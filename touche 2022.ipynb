{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGmfrmDnrwvt",
        "outputId": "f7a37b70-cfc5-4866-883a-6b075a4944da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rank_bm25\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install wget\n",
        "!pip install sense2vec\n",
        "!pip install thinc\n",
        "!python -m spacy download en_core_web_md "
      ],
      "metadata": {
        "id": "UTOoBQhCoK75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FztWiwkDrtff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6452644e-358b-47ed-9b00-775a812f0adc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "from xml.dom import minidom\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import requests\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "import string\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "from tqdm import tqdm\n",
        "from rank_bm25 import BM25Okapi\n",
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_xml(path):\n",
        "  answer_list = []\n",
        "  xmldoc = minidom.parse(path)\n",
        "  itemlist = xmldoc.getElementsByTagName('topics')\n",
        "  topic_list = itemlist[0].getElementsByTagName('topic')\n",
        "  for topic in topic_list:\n",
        "    tuple_for_add = tuple((topic.getElementsByTagName('number')[0].firstChild.nodeValue, topic.getElementsByTagName('title')[0].firstChild.nodeValue,topic.getElementsByTagName('objects')[0].firstChild.nodeValue))\n",
        "    answer_list.append(tuple_for_add)\n",
        "  parsed=pd.DataFrame(answer_list, columns=[\"Number\",\"Title\",\"Objects\"])\n",
        "  return parsed"
      ],
      "metadata": {
        "id": "ANt2m8BLupHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topics=parse_xml(\"/content/drive/MyDrive/Touche/topics-task2.xml\")\n",
        "topics.head()"
      ],
      "metadata": {
        "id": "fL14xsN7vMIL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "43e1a566-3d20-4f23-ae0b-c99e0656ed6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Number                                              Title          Objects\n",
              "0      2            Which is better, a laptop or a desktop?  laptop, desktop\n",
              "1      3                   Which is better, Canon or Nikon?     Canon, Nikon\n",
              "2      8  What are the advantages and disadvantages of P...      PHP, Python\n",
              "3      9                  Why is Linux better than Windows?   Linux, Windows\n",
              "4     12        Train or plane? Which is the better choice?     Train, plane"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b5004c8-60cc-44e9-a1d1-06ba67aa933b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Number</th>\n",
              "      <th>Title</th>\n",
              "      <th>Objects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>Which is better, a laptop or a desktop?</td>\n",
              "      <td>laptop, desktop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>Which is better, Canon or Nikon?</td>\n",
              "      <td>Canon, Nikon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>What are the advantages and disadvantages of P...</td>\n",
              "      <td>PHP, Python</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>Why is Linux better than Windows?</td>\n",
              "      <td>Linux, Windows</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12</td>\n",
              "      <td>Train or plane? Which is the better choice?</td>\n",
              "      <td>Train, plane</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b5004c8-60cc-44e9-a1d1-06ba67aa933b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9b5004c8-60cc-44e9-a1d1-06ba67aa933b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9b5004c8-60cc-44e9-a1d1-06ba67aa933b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jsonObj = pd.read_json(path_or_buf='/content/drive/MyDrive/Touche/touche-task2-passages-version-002.jsonl', lines=True)\n",
        "jsonObj.head()"
      ],
      "metadata": {
        "id": "28mxSnJMsT8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat Noir"
      ],
      "metadata": {
        "id": "iUX55-IlT09f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#extract the uuid from the chat noir url\n",
        "def regex_parser(x):\n",
        "  return(re.search(\".*=(.*)&index.*\",x)[1])\n",
        "jsonObj[\"uuid\"]=jsonObj[\"chatNoirUrl\"].apply(regex_parser)\n",
        "jsonObj.head()"
      ],
      "metadata": {
        "id": "Ve4buJlCPdNC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "564dfe5b-7fff-4719-b09e-1b7b0aba0cf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              id  \\\n",
              "0  clueweb12-0000tw-14-21168___1   \n",
              "1  clueweb12-0000tw-14-21168___2   \n",
              "2  clueweb12-0000tw-14-21168___3   \n",
              "3  clueweb12-0000tw-22-19226___1   \n",
              "4  clueweb12-0000tw-22-19226___2   \n",
              "\n",
              "                                            contents  \\\n",
              "0  Shuga: Love, Sex, Money MTV Shuga Home Swag Bl...   \n",
              "1  We LOVE sending #TeamShuga the exclusives. Ban...   \n",
              "2  Now take note.. because you will be seeing a w...   \n",
              "3  Sex and love: The modern matchmakers | The Eco...   \n",
              "4  But have they? Feb 11th 2012 | from the print ...   \n",
              "\n",
              "                                         chatNoirUrl  \\\n",
              "0  https://chatnoir.eu/cache?uuid=f338e91e-a3e9-5...   \n",
              "1  https://chatnoir.eu/cache?uuid=f338e91e-a3e9-5...   \n",
              "2  https://chatnoir.eu/cache?uuid=f338e91e-a3e9-5...   \n",
              "3  https://chatnoir.eu/cache?uuid=2bf4b08d-2f65-5...   \n",
              "4  https://chatnoir.eu/cache?uuid=2bf4b08d-2f65-5...   \n",
              "\n",
              "                                   uuid  \n",
              "0  f338e91e-a3e9-52ec-bb4c-cac853f4df55  \n",
              "1  f338e91e-a3e9-52ec-bb4c-cac853f4df55  \n",
              "2  f338e91e-a3e9-52ec-bb4c-cac853f4df55  \n",
              "3  2bf4b08d-2f65-5741-80b2-0e6ec18d5505  \n",
              "4  2bf4b08d-2f65-5741-80b2-0e6ec18d5505  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78c3f8ae-81bb-4a4e-9111-c422706c8365\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>contents</th>\n",
              "      <th>chatNoirUrl</th>\n",
              "      <th>uuid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>clueweb12-0000tw-14-21168___1</td>\n",
              "      <td>Shuga: Love, Sex, Money MTV Shuga Home Swag Bl...</td>\n",
              "      <td>https://chatnoir.eu/cache?uuid=f338e91e-a3e9-5...</td>\n",
              "      <td>f338e91e-a3e9-52ec-bb4c-cac853f4df55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>clueweb12-0000tw-14-21168___2</td>\n",
              "      <td>We LOVE sending #TeamShuga the exclusives. Ban...</td>\n",
              "      <td>https://chatnoir.eu/cache?uuid=f338e91e-a3e9-5...</td>\n",
              "      <td>f338e91e-a3e9-52ec-bb4c-cac853f4df55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>clueweb12-0000tw-14-21168___3</td>\n",
              "      <td>Now take note.. because you will be seeing a w...</td>\n",
              "      <td>https://chatnoir.eu/cache?uuid=f338e91e-a3e9-5...</td>\n",
              "      <td>f338e91e-a3e9-52ec-bb4c-cac853f4df55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>clueweb12-0000tw-22-19226___1</td>\n",
              "      <td>Sex and love: The modern matchmakers | The Eco...</td>\n",
              "      <td>https://chatnoir.eu/cache?uuid=2bf4b08d-2f65-5...</td>\n",
              "      <td>2bf4b08d-2f65-5741-80b2-0e6ec18d5505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>clueweb12-0000tw-22-19226___2</td>\n",
              "      <td>But have they? Feb 11th 2012 | from the print ...</td>\n",
              "      <td>https://chatnoir.eu/cache?uuid=2bf4b08d-2f65-5...</td>\n",
              "      <td>2bf4b08d-2f65-5741-80b2-0e6ec18d5505</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78c3f8ae-81bb-4a4e-9111-c422706c8365')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-78c3f8ae-81bb-4a4e-9111-c422706c8365 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-78c3f8ae-81bb-4a4e-9111-c422706c8365');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#chatnoir api intialization\n",
        "chatnoir = \"https://www.chatnoir.eu/api/v1/_search\"\n",
        "attr = {\"apikey\": \"7dd15626-53aa-46c6-bd34-b2feaa2d9d81\",\n",
        "        \"query\": \"hello world\",\n",
        "        \"index\": \"cw12\",\n",
        "        \"pretty\": True,\n",
        "        \"size\":100}"
      ],
      "metadata": {
        "id": "uj_ic1523V_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#search for a topic using chat noir api\n",
        "for x in topics[\"Title\"][0:1]:\n",
        "    attr[\"query\"] = x\n",
        "    print(x)\n",
        "    response = requests.post(chatnoir, data = attr)\n",
        "    res = pd.json_normalize(response.json()[\"results\"])\n",
        "    doc_url = \"https://www.chatnoir.eu/cache?uuid=\"+res['uuid']+\"&index=cw12&raw&plain\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjh6ZF0__UHO",
        "outputId": "d64a0d39-f707-47f1-e080-7f799bc6fb23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Which is better, a laptop or a desktop?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cross referncing the retrieved documents with the given dataset\n",
        "for x in res['uuid']:\n",
        "  print(x)\n",
        "  print(x in jsonObj[\"uuid\"].values)"
      ],
      "metadata": {
        "id": "DsiYPs3mJN-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BM25"
      ],
      "metadata": {
        "id": "14vB_sfE1r3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#functions for preprocessing\n",
        "special_characters=string.punctuation\n",
        "porter_stemmer = PorterStemmer()\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "def spl_chars_removal(lst):\n",
        "  lst1=list()\n",
        "  for element in lst:\n",
        "    str=\"\"\n",
        "    str=\"\".join([i for i in element if i not in special_characters])\n",
        "    lst1.append(str)\n",
        "  return lst1\n",
        "\n",
        "def stopwords_removal_gensim_custom(lst):\n",
        "  tokens_without_sw = [word for word in lst if not word in STOPWORDS]\n",
        "  return tokens_without_sw\n",
        "\n",
        "def stemming(lst):\n",
        "  stem_text = [porter_stemmer.stem(word) for word in lst]\n",
        "  return stem_text\n",
        "\n",
        "def lemmatizer(lst):\n",
        "  lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in lst]\n",
        "  return lemm_text"
      ],
      "metadata": {
        "id": "fl0mp9AXcNU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing the documents (not using apply function due to memory error)\n",
        "preprocessed_documents=[]\n",
        "for i in tqdm(jsonObj[\"contents\"]):\n",
        "  i=i.lower()\n",
        "  z = i.split(\" \")\n",
        "  z=spl_chars_removal(z)\n",
        "  #print(z)\n",
        "  z=stopwords_removal_gensim_custom(z)\n",
        "  #print(z)\n",
        "  z=lemmatizer(z)\n",
        "  z=' '.join(z)\n",
        "  preprocessed_documents.append(z)\n",
        "  #print(z)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmGZWyUYc85b",
        "outputId": "50c1d122-3e4c-45f0-d6de-94ec4813e8e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 868655/868655 [08:27<00:00, 1711.77it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_corpus = [doc.split(\" \") for doc in preprocessed_documents]"
      ],
      "metadata": {
        "id": "PKq3byITrrPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing the queries\n",
        "preprocessed_queries=[]\n",
        "for i in tqdm(topics[\"Title\"]):\n",
        "  i=i.lower()\n",
        "  z = i.split(\" \")\n",
        "  z=spl_chars_removal(z)\n",
        "  #print(z)\n",
        "  #z=stopwords_removal_gensim_custom(z)\n",
        "  #print(z)\n",
        "  z=lemmatizer(z)\n",
        "  z=' '.join(z)\n",
        "  preprocessed_queries.append(z)\n",
        "  #print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QR4SdubqppN",
        "outputId": "4a3c70ed-4365-48fd-d906-e5b5ef16c65f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:00<00:00, 9290.94it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_query=[doc.split(\" \") for doc in preprocessed_queries]\n",
        "tokenized_query[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3jL3KRXoyaA",
        "outputId": "0260b7a7-ecdb-4e68-fe09-fd3dca270820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['which', 'is', 'better', 'a', 'laptop', 'or', 'a', 'desktop']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trainiing the bm25 models on our corpus\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "bm25 =BM25L(tokenized_corpus)"
      ],
      "metadata": {
        "id": "wScAo7k4oWIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fetching the top 1000 documents for a query\n",
        "top_n=bm25.get_top_n(tokenized_query[0],preprocessed_documents, n=1000)\n",
        "doc_scores = bm25.get_scores(tokenized_query[0])"
      ],
      "metadata": {
        "id": "_MFoTI25onWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Predicting Queries from Passages:"
      ],
      "metadata": {
        "id": "7UfwYNVXSoXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "ah2jD2DiUhN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained('castorini/doc2query-t5-base-msmarco')\n",
        "model = T5ForConditionalGeneration.from_pretrained('castorini/doc2query-t5-base-msmarco')\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "1kN8CI1pSnZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_text=jsonObj[\"contents\"][0]\n",
        "input_ids = tokenizer.encode(doc_text, return_tensors='pt').to(device)\n",
        "outputs = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    max_length=64,\n",
        "    do_sample=True,\n",
        "    top_k=10,\n",
        "    num_return_sequences=3)"
      ],
      "metadata": {
        "id": "3RjkbV1FTDSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    print(f'sample {i + 1}: {tokenizer.decode(outputs[i], skip_special_tokens=True)}')"
      ],
      "metadata": {
        "id": "tg7gfLevaPMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#query expansion"
      ],
      "metadata": {
        "id": "OkRnaW4crd9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import tarfile\n",
        "import nltk\n",
        "import wget as wget\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "# from typing import List\n",
        "import spacy\n",
        "\n",
        "# en_core_web_md\n",
        "import string\n",
        "from tqdm import tqdm\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# packages to find similar words by wordembedding and sense2vec\n",
        "from sense2vec import Sense2VecComponent\n",
        "from sense2vec import Sense2Vec  # for standalone\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "random.seed(10)\n",
        "# !/usr/bin/python\n",
        "\n",
        "\n",
        "class QueryExpansion:\n",
        "    def __init__(self, queries: pd.DataFrame, top_syns: int = 5, top_similar: int = 2):\n",
        "        self.df_queries = queries\n",
        "\n",
        "        self.nlp = spacy.load(\"en_core_web_md\")\n",
        "        self.top_syns = top_syns\n",
        "\n",
        "\n",
        "        path = \"/content/drive/MyDrive/Touche/s2v_old\"\n",
        "        self.sense = self.nlp.add_pipe(\"sense2vec\").from_disk(path)\n",
        "        self.standalone_s2v = Sense2Vec().from_disk(path)  # it is not dubplicated\n",
        "\n",
        "        self.tags = [\"CD\", \"JJ\", \"RB\", \"NN\", \"NNS\", \"NNP\", \"NNPS\", \"VB\"]\n",
        "        self.pos_tags = [\"PROPN\", \"VERB\", \"NOUN\", \"NUM\"]\n",
        "\n",
        "        self.top_similar = top_similar\n",
        "\n",
        "    # Query Expansion\n",
        "    def expansion(\n",
        "        self,\n",
        "        relation: bool = False,\n",
        "        synonyms: bool = False,\n",
        "        sensevec: bool = False,\n",
        "        embedded: bool = False,\n",
        "    ):\n",
        "\n",
        "        if relation:\n",
        "            result = []\n",
        "            result = [\n",
        "                *result,\n",
        "                *self.get_comparation_superlation_nouns_from_original_data(),\n",
        "            ]\n",
        "            self.df_queries = pd.concat(\n",
        "                [\n",
        "                    self.df_queries,\n",
        "                    pd.DataFrame(result, columns=[\"TopicID\", \"topic\", \"query\", \"tag\"]),\n",
        "                ]\n",
        "            )\n",
        "\n",
        "        if synonyms:\n",
        "            result = []\n",
        "            result = [*result, *self.synonyms()]\n",
        "            self.df_queries = pd.concat(\n",
        "                [\n",
        "                    self.df_queries,\n",
        "                    pd.DataFrame(result, columns=[\"TopicID\", \"topic\", \"query\", \"tag\"]),\n",
        "                ]\n",
        "            )\n",
        "\n",
        "        if sensevec:\n",
        "            result = []\n",
        "            result = [*result, *self.similarwords_sensevec()]\n",
        "            self.df_queries = pd.concat(\n",
        "                [\n",
        "                    self.df_queries,\n",
        "                    pd.DataFrame(result, columns=[\"TopicID\", \"topic\", \"query\", \"tag\"]),\n",
        "                ]\n",
        "            )\n",
        "        if embedded:\n",
        "            result = []\n",
        "            result = [*result, *self.similarwords_wordembedding()]\n",
        "            self.df_queries = pd.concat(\n",
        "                [\n",
        "                    self.df_queries,\n",
        "                    pd.DataFrame(result, columns=[\"TopicID\", \"topic\", \"query\", \"tag\"]),\n",
        "                ]\n",
        "            )\n",
        "\n",
        "        return self.df_queries\n",
        "\n",
        "    def similarwords_replace(self, query, similar_words):\n",
        "        import copy\n",
        "\n",
        "        expanded_queries = []\n",
        "        for word, similar_words in similar_words.items():\n",
        "            for similar_word in similar_words:\n",
        "                new_query = copy.deepcopy(query).replace(word, similar_word)\n",
        "                expanded_queries.append(new_query)\n",
        "        return expanded_queries\n",
        "\n",
        "    def similarwords_sensevec(self):\n",
        "        result = []\n",
        "\n",
        "        for original_query in tqdm(\n",
        "            list(self.df_queries[\"topic\"].unique()), desc=\"Sensevec progress\"\n",
        "        ):\n",
        "\n",
        "            original_topicid = self.df_queries[\n",
        "                self.df_queries[\"topic\"] == original_query\n",
        "            ].iloc[0][\"TopicID\"]\n",
        "\n",
        "            doc = self.nlp(original_query)\n",
        "            expanded_queries = []\n",
        "            similar_words = {}\n",
        "            for token in doc:\n",
        "                top_similar_words = []\n",
        "                if token.tag_ in self.tags or token.pos_ in self.pos_tags:\n",
        "                    if token.lemma_ not in STOP_WORDS or token.text not in STOP_WORDS:\n",
        "                        try:\n",
        "                            for e in token._.s2v_most_similar(self.top_similar):\n",
        "                                word = e[0][\n",
        "                                    0\n",
        "                                ].strip()  # get only word from ((word, tag), proba)\n",
        "                                if (word != token.text) and (\n",
        "                                    self.nlp(word)[0].lemma_ != token.lemma_\n",
        "                                ):\n",
        "                                    top_similar_words.append(word)\n",
        "                        except ValueError as err:\n",
        "                            print(err)\n",
        "                            for ent in doc.ents:\n",
        "                                if ent.text == token.text:\n",
        "                                    try:\n",
        "                                        for e in ent._.s2v_most_similar(\n",
        "                                            self.top_similar\n",
        "                                        ):\n",
        "                                            word = e[0][\n",
        "                                                0\n",
        "                                            ].strip()  # get only word from ((word, tag), proba)\n",
        "                                            if (word != token.text) and (\n",
        "                                                self.nlp(word)[0].lemma_ != token.lemma_\n",
        "                                            ):\n",
        "                                                top_similar_words.append(word)\n",
        "\n",
        "                                    except Exception as err:\n",
        "                                        print(err)\n",
        "                                        query = token._.s2v_other_senses[\n",
        "                                            0\n",
        "                                        ]  # get first similar words by entity_tag\n",
        "                                        for e in self.standalone_s2v.most_similar(\n",
        "                                            query, n=self.top_similar\n",
        "                                        ):\n",
        "                                            word = (\n",
        "                                                e[0].split(\"|\")[0].strip()\n",
        "                                            )  # get only word from (word|tag, proba)\n",
        "                                            if (word != token.text) and (\n",
        "                                                self.nlp(word)[0].lemma_ != token.lemma_\n",
        "                                            ):\n",
        "                                                top_similar_words.append(word)\n",
        "\n",
        "                        similar_words[token.text] = list(set(top_similar_words))\n",
        "            expanded_queries = self.similarwords_replace(original_query, similar_words)\n",
        "            i = 1\n",
        "            for new_query in expanded_queries:\n",
        "                result.append(\n",
        "                    [original_topicid, original_query, new_query, \"sensevec_\" + str(i)]\n",
        "                )\n",
        "                i = i + 1\n",
        "        return result\n",
        "\n",
        "    def remove_punc(self, query: str):\n",
        "        table = str.maketrans(dict.fromkeys(string.punctuation))\n",
        "        title = query.translate(table)\n",
        "        return str(title)\n",
        "\n",
        "    def synonyms(self):\n",
        "        result = []\n",
        "\n",
        "        for query in tqdm(\n",
        "            list(self.df_queries[\"topic\"].unique()), desc=\"Synonyms progress\"\n",
        "        ):\n",
        "            original_topicid = self.df_queries[self.df_queries[\"topic\"] == query].iloc[\n",
        "                0\n",
        "            ][\"TopicID\"]\n",
        "\n",
        "            new_title = self.remove_punc(query)\n",
        "            syn_pro_title = list()\n",
        "            temp = new_title\n",
        "            new_title = self.nlp(new_title)\n",
        "            for token in new_title:\n",
        "                syn_token = self.find_syns_word(token)\n",
        "                syn_pro_title.extend(\n",
        "                    [syn for syn in list(set(syn_token)) if syn != str(token.text)]\n",
        "                )  # distinct and remove the same words\n",
        "            # print(syn_pro_title)\n",
        "            # synonyms_by_titles.writelines(\" \".join(list(set(syn_pro_title))) + \"\\n\")\n",
        "            # ToDo temp(org) + syns or only syns?\n",
        "            result.append(\n",
        "                [\n",
        "                    original_topicid,\n",
        "                    query,\n",
        "                    temp + \" \" + \" \".join(list(set(syn_pro_title))),\n",
        "                    \"syns\",\n",
        "                ]\n",
        "            )\n",
        "        return result\n",
        "\n",
        "    def find_syns_word(self, token: str):\n",
        "        syn_token = []\n",
        "        if token.pos_ == \"NOUN\":\n",
        "            # ToDo automate wordnet install\n",
        "            for synset in wordnet.synsets(token.lemma_):\n",
        "                for lemma in synset.lemmas()[: self.top_syns]:  # top 5 synonyms\n",
        "                    if (\n",
        "                        \"_\" not in lemma.name()\n",
        "                    ):  # not include the words with _ ex: basketball_game\n",
        "                        syn_token.append(lemma.name())\n",
        "                    else:\n",
        "                        for w in lemma.name().split(\"_\"):\n",
        "                            if w not in STOP_WORDS:\n",
        "                                syn_token.append(\n",
        "                                    w\n",
        "                                )  # add words with _ to two words ex. laptop_computer -> laptop and computer\n",
        "        syn_token = [w for w in syn_token if w != \" \" and len(w) != 0]\n",
        "\n",
        "        # ToDo remove random influence\n",
        "        if len(syn_token) > 5:\n",
        "            return random.sample(\n",
        "                syn_token, k=5\n",
        "            )  # after top 5 synonyms + splited words -> long titles -> reducing the syns random with 5\n",
        "        else:\n",
        "            return syn_token\n",
        "\n",
        "    def get_comparation_superlation_nouns_from_original_data(self):\n",
        "        result = []\n",
        "\n",
        "        for query in tqdm(\n",
        "            list(self.df_queries[\"topic\"].unique()), desc=\"Relation progress\"\n",
        "        ):\n",
        "            original_topicid = self.df_queries[self.df_queries[\"topic\"] == query].iloc[\n",
        "                0\n",
        "            ][\"TopicID\"]\n",
        "\n",
        "            nouns_as_string = []\n",
        "            doc = self.nlp(query)\n",
        "            annotations = [\n",
        "                \"CC\",\n",
        "                \"CD\",\n",
        "                \"JJ\",\n",
        "                \"JJR\",\n",
        "                \"JJS\",\n",
        "                \"RB\",\n",
        "                \"RBR\",\n",
        "                \"RBS\",\n",
        "                \"NN\",\n",
        "                \"NNS\",\n",
        "                \"NNP\",\n",
        "                \"NNPS\",\n",
        "                \"VB\",\n",
        "            ]\n",
        "            for token in doc:\n",
        "                if token.tag_ in annotations:\n",
        "                    nouns_as_string.append(token.text)\n",
        "            result.append(\n",
        "                [original_topicid, query, \" \".join(nouns_as_string), \"annotation\"]\n",
        "            )\n",
        "        return result\n",
        "\n",
        "    def similarwords_wordembedding(self):\n",
        "        result = []\n",
        "        for query in tqdm(\n",
        "            list(self.df_queries[\"topic\"].unique()), desc=\"Embeddings progress\"\n",
        "        ):\n",
        "            original_topicid = self.df_queries[self.df_queries[\"topic\"] == query].iloc[\n",
        "                0\n",
        "            ][\"TopicID\"]\n",
        "\n",
        "            doc = self.nlp(query)\n",
        "            # expanded queries\n",
        "            expanded_queries = []\n",
        "            similar_words = {}\n",
        "            for token in doc:\n",
        "                top_similar_words = []\n",
        "                if token.tag_ in self.tags or token.pos_ in self.pos_tags:\n",
        "                    if token.lemma_ not in STOP_WORDS or token.text not in STOP_WORDS:\n",
        "                        try:\n",
        "                            word = token.lemma_\n",
        "\n",
        "                            try:\n",
        "                                key = self.nlp.vocab.strings[word]\n",
        "                                vector = self.nlp.vocab.vectors[key]\n",
        "                                vector_asarray = np.asarray([vector])\n",
        "                                ms = self.nlp.vocab.vectors.most_similar(\n",
        "                                    vector_asarray, n=self.top_similar\n",
        "                                )\n",
        "                                # print(ms)\n",
        "                                similar_embedding = [\n",
        "                                    self.nlp.vocab.strings[w] for w in ms[0][0]\n",
        "                                ]  # get only text from most_similar\n",
        "                                # checking again if similar words are the same word\n",
        "                                for word in similar_embedding:\n",
        "                                    if (word != token.text) and (\n",
        "                                        self.nlp(word)[0].lemma_ != token.lemma_\n",
        "                                    ):\n",
        "                                        top_similar_words.append(\n",
        "                                            self.nlp(word)[0].lemma_.lower()\n",
        "                                        )\n",
        "                            except KeyError as err:\n",
        "                                print(err)\n",
        "                        except ValueError as err:\n",
        "                            print(err)\n",
        "\n",
        "                        similar_words[token.text] = list(\n",
        "                            set(top_similar_words)\n",
        "                        )  # only unique words\n",
        "\n",
        "            # replace with similar words for new queries.\n",
        "            expanded_queries = self.similarwords_replace(query, similar_words)\n",
        "\n",
        "            i = 1\n",
        "            for new_query in expanded_queries:\n",
        "                result.append(\n",
        "                    [original_topicid, query, new_query, \"embedded_\" + str(i)]\n",
        "                )\n",
        "                i = i + 1\n",
        "        return result\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "\n",
        "#     topics = [\n",
        "#         \"What is the difference between sex and love?\",\n",
        "#         \"Which is the highest mountain in the world?\",\n",
        "#         \"Which is better, a laptop or a desktop?\",\n",
        "#     ]\n",
        "\n",
        "#     topics = [\n",
        "#         \"What is the difference between sex and love?\",\n",
        "#         \"Which is better, a laptop or a desktop?\",\n",
        "#         \"Which is better, Canon or Nikon?\",\n",
        "#         \"What are the best dish detergents?\",\n",
        "#         \"What are the best cities to live in?\",\n",
        "#         \"What is the longest river in the U.S.?\",\n",
        "#         \"Which is healthiest: coffee, green tea or black tea and why?\",\n",
        "#         \"What are the advantages and disadvantages of PHP over Python and vice versa?\",\n",
        "#         \"Why is Linux better than Windows?\",\n",
        "#         \"How to sleep better?\",\n",
        "#         \"Should I buy an LCD TV or a plasma TV?\",\n",
        "#         \"Train or plane? Which is the better choice?\",\n",
        "#         \"What is the highest mountain on Earth?\",\n",
        "#         \"Should one prefer Chinese medicine or Western medicine?\",\n",
        "#         \"What are the best washing machine brands?\",\n",
        "#         \"Should I buy or rent?\",\n",
        "#         \"Do you prefer cats or dogs, and why?\",\n",
        "#         \"What is the better way to grill outdoors: gas or charcoal?\",\n",
        "#         \"Which is better, MAC or PC?\",\n",
        "#         \"What is better: to use a brush or a sponge?\",\n",
        "#         \"Which is better, Linux or Microsoft?\",\n",
        "#         \"Which is better, Pepsi or Coke?\",\n",
        "#         \"What is better, Google search or Yahoo search?\",\n",
        "#         \"Which one is better, Netflix or Blockbuster?\",\n",
        "#         \"Which browser is better, Internet Explorer or Firefox?\",\n",
        "#         \"Which is a better vehicle: BMW or Audi?\",\n",
        "#         \"Which one is better, an electric stove or a gas stove?\",\n",
        "#         \"What planes are best, Boeing or Airbus?\",\n",
        "#         \"Which is better, Disneyland or Disney World?\",\n",
        "#         \"Should I buy an Xbox or a PlayStation?\",\n",
        "#         \"Which has more caffeine, coffee or tea?\",\n",
        "#         \"Which is better, LED or LCD Reception Displays?\",\n",
        "#         \"What is better: ASP or PHP?\",\n",
        "#         \"What is better for the environment, a real or a fake Christmas tree?\",\n",
        "#         \"Do you prefer tampons or pads?\",\n",
        "#         \"What IDE is better for Java: NetBeans or Eclipse?\",\n",
        "#         \"Is OpenGL better than Direct3D in terms of portability to different platforms?\",\n",
        "#         \"What are the differences between MySQL and PostgreSQL in performance?\",\n",
        "#         \"Is Java code more readable than code written in Scala?\",\n",
        "#         \"Which operating system has better performance: Windows 7 or Windows 8?\",\n",
        "#         \"Which smartphone has a better battery life: Xperia or iPhone?\",\n",
        "#         \"Which four wheel truck is better: Ford or Toyota?\",\n",
        "#         \"Should I prefer a Leica camera over Nikon for portrait photographs?\",\n",
        "#         \"Which company has a larger capitalization: Apple or Microsoft?\",\n",
        "#         \"Which laptop has a better durability: HP or Dell?\",\n",
        "#         \"Which beverage has more calories per glass: beer or cider?\",\n",
        "#         \"Is admission rate in Stanford higher than that of MIT?\",\n",
        "#         \"Is pasta healthier than pizza?\",\n",
        "#         \"Which city is more expensive to live in: San Francisco or New York?\",\n",
        "#         \"Whose salary is higher: basketball or soccer players?\",\n",
        "#     ]\n",
        "\n",
        "#     df = pd.DataFrame(\n",
        "#         list(zip(range(0,len(topics)),topics, topics, len(topics) * [\"original\"])),\n",
        "#         columns=[\"TopicID\",\"topic\", \"query\", \"tag\"],\n",
        "#     )\n",
        "#     print(df)\n",
        "\n",
        "#     pd.set_option(\"display.max_columns\", 4)\n",
        "#     expansion = QueryExpansion(df)\n",
        "#     df_relation = expansion.expansion(\n",
        "#         relation=True, synonyms=True, sensevec=True, embedded=True\n",
        "#     )\n",
        "\n",
        "#     for q in topics:\n",
        "#         print(q)\n",
        "#         print(df_relation[df_relation[\"topic\"] == q])\n",
        "#         print(100 * \"=\")"
      ],
      "metadata": {
        "id": "J2Z4w-9kb0-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(\n",
        "        list(zip(range(0,len(topics)),topics[\"Objects\"], topics[\"Title\"], len(topics) * [\"original\"])),\n",
        "        columns=[\"TopicID\",\"query\", \"topic\", \"tag\"],)"
      ],
      "metadata": {
        "id": "HlyCfCa7rhg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expansion = QueryExpansion(df)\n",
        "df_relation = expansion.expansion(relation=True, synonyms=True, sensevec=True, embedded=True)"
      ],
      "metadata": {
        "id": "5vOvOX6VrxME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_relation"
      ],
      "metadata": {
        "id": "ldSFQeI4sA7X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "outputId": "bdecb341-1aea-4241-9d12-fa57aee0ef4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     TopicID                                              query  \\\n",
              "0          0                                    laptop, desktop   \n",
              "1          1                                       Canon, Nikon   \n",
              "2          2                                        PHP, Python   \n",
              "3          3                                     Linux, Windows   \n",
              "4          4                                       Train, plane   \n",
              "..       ...                                                ...   \n",
              "232       48  Which is more environmentally friendly, a hybr...   \n",
              "233       49      Should I learn pyside or R for data analysis?   \n",
              "234       49      Should I learn Python or ¤ for data analysis?   \n",
              "235       49   Should I learn Python or R for dataset analysis?   \n",
              "236       49  Should I learn Python or R for data climatolog...   \n",
              "\n",
              "                                                 topic         tag  \n",
              "0              Which is better, a laptop or a desktop?    original  \n",
              "1                     Which is better, Canon or Nikon?    original  \n",
              "2    What are the advantages and disadvantages of P...    original  \n",
              "3                    Why is Linux better than Windows?    original  \n",
              "4          Train or plane? Which is the better choice?    original  \n",
              "..                                                 ...         ...  \n",
              "232  Which is more environmentally friendly, a hybr...  embedded_8  \n",
              "233      Should I learn Python or R for data analysis?  embedded_1  \n",
              "234      Should I learn Python or R for data analysis?  embedded_2  \n",
              "235      Should I learn Python or R for data analysis?  embedded_3  \n",
              "236      Should I learn Python or R for data analysis?  embedded_4  \n",
              "\n",
              "[621 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c2cf26eb-187f-4cbe-a212-77e823a24992\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TopicID</th>\n",
              "      <th>query</th>\n",
              "      <th>topic</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>laptop, desktop</td>\n",
              "      <td>Which is better, a laptop or a desktop?</td>\n",
              "      <td>original</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Canon, Nikon</td>\n",
              "      <td>Which is better, Canon or Nikon?</td>\n",
              "      <td>original</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>PHP, Python</td>\n",
              "      <td>What are the advantages and disadvantages of P...</td>\n",
              "      <td>original</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Linux, Windows</td>\n",
              "      <td>Why is Linux better than Windows?</td>\n",
              "      <td>original</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Train, plane</td>\n",
              "      <td>Train or plane? Which is the better choice?</td>\n",
              "      <td>original</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>48</td>\n",
              "      <td>Which is more environmentally friendly, a hybr...</td>\n",
              "      <td>Which is more environmentally friendly, a hybr...</td>\n",
              "      <td>embedded_8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>49</td>\n",
              "      <td>Should I learn pyside or R for data analysis?</td>\n",
              "      <td>Should I learn Python or R for data analysis?</td>\n",
              "      <td>embedded_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>49</td>\n",
              "      <td>Should I learn Python or ¤ for data analysis?</td>\n",
              "      <td>Should I learn Python or R for data analysis?</td>\n",
              "      <td>embedded_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>49</td>\n",
              "      <td>Should I learn Python or R for dataset analysis?</td>\n",
              "      <td>Should I learn Python or R for data analysis?</td>\n",
              "      <td>embedded_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>49</td>\n",
              "      <td>Should I learn Python or R for data climatolog...</td>\n",
              "      <td>Should I learn Python or R for data analysis?</td>\n",
              "      <td>embedded_4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>621 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2cf26eb-187f-4cbe-a212-77e823a24992')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c2cf26eb-187f-4cbe-a212-77e823a24992 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c2cf26eb-187f-4cbe-a212-77e823a24992');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CfKaDscr72gC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "parse_topics.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "iUX55-IlT09f",
        "14vB_sfE1r3p",
        "7UfwYNVXSoXc",
        "OkRnaW4crd9T"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}