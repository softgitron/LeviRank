{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "initial-retrieval-prototyping-and-analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4j85Y-nmGV7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "721af742-89ae-41fd-db8c-9dade1fe345d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cleaning sample_data directory\n",
        "!rm -r sample_data"
      ],
      "metadata": {
        "id": "Hj7M-YF9A3n5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/My\\ Drive/touche-2022-prototyping"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxPrdX68Auuf",
        "outputId": "ffa5f75f-d14b-4d6c-a6bc-6f0ff1c936de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial-retrieval-prototyping-and-analysis.ipynb\n",
            "touche-task2-passages-version-002-expanded-with-doc-t5-query.jsonl\n",
            "touche-task2-passages-version-002.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One Time Exection.\n",
        "# extracting files and converting them to 'tar.gz' files.\n",
        "# !gzip -d drive/My\\ Drive/touche-2022-prototyping/touche-task2-passages-version-002-expanded-with-doc-t5-query.jsonl.gz\n",
        "# !gzip -d drive/My\\ Drive/touche-2022-prototyping/touche-task2-passages-version-002.jsonl.gz"
      ],
      "metadata": {
        "id": "JHSRAOk5otk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# installing linux related stuff for pyserini\n",
        "# removing error \"ImportError: No module named '_swigfaiss\"\n",
        "# Reference Link: https://github.com/facebookresearch/faiss/issues/821\n",
        "!sudo apt-get install libomp-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23SsTA0a_tNU",
        "outputId": "3116e6eb-b7a8-427e-9cce-de8678844fbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libomp5\n",
            "Suggested packages:\n",
            "  libomp-doc\n",
            "The following NEW packages will be installed:\n",
            "  libomp-dev libomp5\n",
            "0 upgraded, 2 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 239 kB of archives.\n",
            "After this operation, 804 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp-dev amd64 5.0.1-1 [5,088 B]\n",
            "Fetched 239 kB in 1s (301 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 155335 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Selecting previously unselected package libomp-dev.\n",
            "Preparing to unpack .../libomp-dev_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp-dev (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp-dev (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# installing important packages for analyzing the code.\n",
        "!pip install jsonlines\n",
        "!pip install pyserini\n",
        "!pip install faiss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb1hvFTCv_hK",
        "outputId": "bd70a429-790e-4775-8072-927a7a887130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jsonlines\n",
            "  Downloading jsonlines-3.0.0-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonlines) (3.10.0.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from jsonlines) (21.4.0)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-3.0.0\n",
            "Collecting pyserini\n",
            "  Downloading pyserini-0.16.0-py3-none-any.whl (84.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 84.6 MB 113 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from pyserini) (1.4.1)\n",
            "Collecting lightgbm>=3.3.2\n",
            "  Downloading lightgbm-3.3.2-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 34.0 MB/s \n",
            "\u001b[?25hCollecting transformers>=4.6.0\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 24.8 MB/s \n",
            "\u001b[?25hCollecting pyjnius>=1.4.0\n",
            "  Downloading pyjnius-1.4.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 32.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from pyserini) (1.3.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from pyserini) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.7/dist-packages (from pyserini) (1.21.5)\n",
            "Collecting onnxruntime>=1.8.1\n",
            "  Downloading onnxruntime-1.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 30.2 MB/s \n",
            "\u001b[?25hCollecting nmslib>=2.1.1\n",
            "  Downloading nmslib-2.1.1-cp37-cp37m-manylinux2010_x86_64.whl (13.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.5 MB 33.1 MB/s \n",
            "\u001b[?25hCollecting spacy>=3.2.1\n",
            "  Downloading spacy-3.2.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 20.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pyserini) (4.63.0)\n",
            "Requirement already satisfied: Cython>=0.29.21 in /usr/local/lib/python3.7/dist-packages (from pyserini) (0.29.28)\n",
            "Collecting sentencepiece>=0.1.95\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 37.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=3.3.2->pyserini) (0.37.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from nmslib>=2.1.1->pyserini) (5.4.8)\n",
            "Collecting pybind11<2.6.2\n",
            "  Downloading pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n",
            "\u001b[K     |████████████████████████████████| 188 kB 39.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=1.8.1->pyserini) (2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=1.8.1->pyserini) (3.17.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->pyserini) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->pyserini) (2018.9)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from pyjnius>=1.4.0->pyserini) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->pyserini) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->pyserini) (1.1.0)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
            "  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (0.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (21.3)\n",
            "Collecting thinc<8.1.0,>=8.0.12\n",
            "  Downloading thinc-8.0.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (653 kB)\n",
            "\u001b[K     |████████████████████████████████| 653 kB 43.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (3.10.0.2)\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 35.2 MB/s \n",
            "\u001b[?25hCollecting langcodes<4.0.0,>=3.2.0\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 49.5 MB/s \n",
            "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.6\n",
            "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (57.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (2.11.3)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
            "  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (0.4.1)\n",
            "Collecting typer<0.5.0,>=0.3.0\n",
            "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (2.0.6)\n",
            "Collecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (3.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (1.0.6)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 36.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy>=3.2.1->pyserini) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy>=3.2.1->pyserini) (3.0.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy>=3.2.1->pyserini) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (1.24.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 40.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->pyserini) (4.11.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->pyserini) (3.6.0)\n",
            "Collecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 34.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->pyserini) (2019.12.20)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 40.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy>=3.2.1->pyserini) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy>=3.2.1->pyserini) (2.0.1)\n",
            "Installing collected packages: catalogue, typer, srsly, pyyaml, pydantic, tokenizers, thinc, spacy-loggers, spacy-legacy, sacremoses, pybind11, pathy, langcodes, huggingface-hub, transformers, spacy, sentencepiece, pyjnius, onnxruntime, nmslib, lightgbm, pyserini\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "Successfully installed catalogue-2.0.6 huggingface-hub-0.4.0 langcodes-3.3.0 lightgbm-3.3.2 nmslib-2.1.1 onnxruntime-1.10.0 pathy-0.6.1 pybind11-2.6.1 pydantic-1.8.2 pyjnius-1.4.1 pyserini-0.16.0 pyyaml-6.0 sacremoses-0.0.49 sentencepiece-0.1.96 spacy-3.2.3 spacy-legacy-3.0.9 spacy-loggers-1.0.1 srsly-2.4.2 thinc-8.0.15 tokenizers-0.11.6 transformers-4.17.0 typer-0.4.0\n",
            "Collecting faiss\n",
            "  Downloading faiss-1.5.3-cp37-cp37m-manylinux1_x86_64.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from faiss) (1.21.5)\n",
            "Installing collected packages: faiss\n",
            "Successfully installed faiss-1.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import statements\n",
        "import pandas as pd\n",
        "import jsonlines"
      ],
      "metadata": {
        "id": "tV1M4Yu2DKaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# original corpus\n",
        "# corpus_list = list(jsonlines.open('drive/My Drive/touche-2022-prototyping/touche-task2-passages-version-002.jsonl'))"
      ],
      "metadata": {
        "id": "B7Gb5urFDKcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# query expansion corpus\n",
        "qcorpus_list = list(jsonlines.open('drive/My Drive/touche-2022-prototyping/touche-task2-passages-version-002-expanded-with-doc-t5-query.jsonl'))"
      ],
      "metadata": {
        "id": "ZWRbfZ-jotq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# printing demo query\n",
        "qcorpus_list[0]"
      ],
      "metadata": {
        "id": "jSdmIgqlmJGO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e75fb74f-e2a8-4f48-f9cc-d964b69bd5e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'chatNoirUrl': 'https://chatnoir.eu/cache?uuid=25e04d49-8df7-58c9-8fae-c5bd54a070ba&index=cw12&raw&plain',\n",
              " 'contents': \"Do Asian-Americans Face Bias in Admissions at Elite Colleges? - NYTimes.com Home Page Today's Paper Video Most Popular Times Topics Search All NYTimes.com Education World U.S. Politics Education Bay Area Chicago Texas N.Y. / Region Business Technology Science Health Sports Opinion Arts Style Travel Jobs Real Estate Autos February 8, 2012, 1:43 pm Do Asian-Americans Face Bias in Admissions at Elite Colleges? By DANIEL E. SLOTNIK 6:08 p.m. | Updated A statement from Princeton was added to the story. The Department of Education’s Office for Civil Rights is examining complaints thatHarvard and Princeton have discriminated against Asian-American undergraduate applicants, highlighting a concern of many Asian-American parents. The inquiry was first reported by Bloomberg News.<query> do asian americans face bias in admissions</query>\",\n",
              " 'id': 'clueweb12-0000tw-00-14115___1'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir sample_collection_jsonl\n",
        "!mkdir indexes\n",
        "!mkdir indexes/sample_collection_jsonl"
      ],
      "metadata": {
        "id": "Dce45nMb5qLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = jsonlines.open('sample_collection_jsonl/documents.jsonl', 'w')\n",
        "for vals in qcorpus_list:\n",
        "    output.write({\n",
        "        'id': vals['id'],\n",
        "        'contents': vals['contents']\n",
        "    })"
      ],
      "metadata": {
        "id": "7_sMoNep3b22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10 sample_collection_jsonl/documents.jsonl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0LGC18t4uTd",
        "outputId": "a2cc0658-f832-413b-d5cf-8cad47f67e9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"id\": \"clueweb12-0000tw-00-14115___1\", \"contents\": \"Do Asian-Americans Face Bias in Admissions at Elite Colleges? - NYTimes.com Home Page Today's Paper Video Most Popular Times Topics Search All NYTimes.com Education World U.S. Politics Education Bay Area Chicago Texas N.Y. / Region Business Technology Science Health Sports Opinion Arts Style Travel Jobs Real Estate Autos February 8, 2012, 1:43 pm Do Asian-Americans Face Bias in Admissions at Elite Colleges? By DANIEL E. SLOTNIK 6:08 p.m. | Updated A statement from Princeton was added to the story. The Department of Education’s Office for Civil Rights is examining complaints thatHarvard and Princeton have discriminated against Asian-American undergraduate applicants, highlighting a concern of many Asian-American parents. The inquiry was first reported by Bloomberg News.<query> do asian americans face bias in admissions</query>\"}\n",
            "{\"id\": \"clueweb12-0000tw-00-14115___10\", \"contents\": \"By insisting on upholding affirmative action in college admissions, they ensure that America continues to be an extremely race sensitive society where everything is based on race. For Asian-Americans, I say take heart. Competition only makes you stronger. And who cares about the Ivy League, their mission is never to educate the best. Their main mission is to live off their “old money” prestige by rubber stamping the diploma of the offsprings of the rich and powerful, before ushering them into pre-ordained careers on Wall Street and Washington DC to further enhance the schools reputation and future coffer. A few “colored folks” get to come along for the ride just so they could claim equality. At the end of the day, an ivy league degree only matters if you want to a degree of the idle rich, i.e. a liberal arts degree, before going into law, wall street, politics or academia, all are careers that depend heavily on connections.<query> why is the ivy league important</query>\"}\n",
            "{\"id\": \"clueweb12-0000tw-00-14115___11\", \"contents\": \"If you don’t have a rich/famous daddy or mommy, and want a career in STEM or accounting, i.e. a major that actually leads to a real job, you should just go to a top school for the field you are interested in, or go to a big state university. None of the ivies are considered top schools in any STEM field. Let the idle rich have their own paradise without it being contaminated by the commoners. — Shameful Discrimination 3. February 8, 2012 3:34 pm Link I agree that it is most likely a myth. As is the completely academically focused Asian with no ECs. I think it’s likely that, as one person in the article pointed out, Asians as a group score higher on standardized tests and maybe even GPA. Yet if schools truly do a holistic review of candidates and pick them on an overall basis, if one were to look only at scores, it would look like Asians were being unfairly discriminated against.<query> what is the best school for stem</query>\"}\n",
            "{\"id\": \"clueweb12-0000tw-00-14115___12\", \"contents\": \"It’s speculative to have an opinion either way, and it is definitely worth looking at, to ensure fairness. Maybe the non-Asians as a group have more legacies, athletes, etc. than Asians and the non-Asians have lower scores as a group when compared to Asians – that may be all that is creating the perception of bias. Schools do want more than just test scores these days, for better or for worse. They want a “well-rounded student body” they say. Admissions at elite colleges is so difficult anymore, it’s no wonder that people look for reasons. My son has spectacular numbers, is an athlete, student government, clubs, volunteers, etc. yet got rejected at Stanford REA this year. I wasn’t surprised at all, as he has no serious “hook.” And the admission rate is ridiculously low after you subtract athletes, legacies, etc.<query> why are non asians more selective</query>\"}\n",
            "{\"id\": \"clueweb12-0000tw-00-14115___13\", \"contents\": \"Probably 2-3 percent. Such is life. — Kent Clarkfield 4. February 8, 2012 4:20 pm Link Yes, and it’s funny how diversity cuts only when it comes to academics. With sports, it has to all be about talent. Do people care about diversity there? In fact with Jeremy Lin blowing up recently, people should examine his road to where he is now. He is definitely the minority AND he had great success all the way from High School on but met adversity. Winning states in California and not getting recruited seriously for college play? Ethnicity a strike in sports, in academics, …either go all fair all the way or strive for diversity all the way. Don’t mix and match as you see convenient. — AsianM 5. February 8, 2012 5:19 pm Link In his statement, “What may seem to be racial bias “is actually caused by too many people applying to college,”” Mr. Jon Reider seems to say the complaint is because the total number of Asians getting rejected.<query> what percentage of college applicants are african american</query>\"}\n",
            "{\"id\": \"clueweb12-0000tw-00-14115___14\", \"contents\": \"That is not bias. The point is “all things equal, Asians are not getting in as some other ethnic groups are.” He is right to say, “We like to put blame on things.” However, to this reader, he is actually blaming people making the complaints. When he said, “I have not seen any pattern at selective colleges in this regard,” maybe the interviewer should have pointed him to the Espenshade study. As about Mr. Greene, his statement below seems to say that if one looks at the majors individually, then the the Espenshade type of study will show the claim of bias is a myth. I hope he can prove this IS a myth as that will be the best for everyone involved. This is what he said: “traditional emphasis on “Asian-American families directing their children to math, science, engineering and maybe business” could work against their admissions chances because “there’s not a broad representation of students applying for humanities, English, the arts.” — That Was Zen 6.<query> what is the espenshade study</query>\"}\n",
            "{\"id\": \"clueweb12-0000tw-00-14115___15\", \"contents\": \"February 8, 2012 5:31 pm Link It would be helpful to get some more detailed information, both application/admission statistics and descriptions of schools’ admissions processes, to evaluate this disturbing piece. The place to start would be simple statistics of the sort that make up a prima facie disparate impact claim in the world of employment discrimination litigation: for each school, what are the respective percentages of each racial/ethnic category in the applicant pool and the admitted group? Then, how do they break down into cohorts by SAT/ACT score and grade point average? To deal with some of the arguments by those quoted in the article (including Espenshade, who seems to be backpedaling away from his work in order to continue to support affirmative action for certain groups), how do factors other than race/ethnicity factor into the admissions decision?<query> what is the disparate impact claim</query>\"}\n",
            "{\"id\": \"clueweb12-0000tw-00-14115___16\", \"contents\": \"Are race/ethnicity looked at first in making a rough cut? Are the soft criteria like “leadership potential” looked at first? Are the objective and subjective factors all considered simultaneously? Does the admissions office have a target range based on proportional representation? Do they have a floor below which they will not go to pick up underrepresented minorities? Crucially, is the candidate’s race/ethnicity known to the admissions decision-makers when they are making subjective evaluations about “hooks”? In short, which element or elements of the admission process are causing the disparate impact, and why? Mr. Reider’s point that you need to control for each variable and compare apples to apples is sound as far as it goes, but it begs the question if points assigned for subjective variables are skewed to counter built-in headwinds as to test scores and grades so as to justify a racially pre-determined outcome.<query> which element of the admissions process is causing the disparate impact, and why?</query>\"}\n",
            "{\"id\": \"clueweb12-0000tw-00-14115___17\", \"contents\": \"One would really need an independent assessment of the applicants’ credentials for “leadership,” “creativity,” etc. to determine if they were fairly weighted. — Andrew 7. February 8, 2012 6:24 pm Link People want to believe that admissions is solely a numbers game–the kid with a 2300 SAT and 3.9 GPA should be admitted before a kid with a 2150 SAT and a 3.8 GPA. But for admissions people, those numbers are essentially identical. What makes the difference is what else those kids have done beyond the numbers — maybe the 2300 SAT kid is a member of the math team and plays piano, and the 2150 SAT kid has founded a literary magazine, has volunteered for many years for Habitat, has worked a summer job, and is a member of the math team and plays piano.<query> what is the difference between a 2300 sat and a 2150 s\"}\n",
            "{\"id\": \"clueweb12-0000tw-00-14115___18\", \"contents\": \"The second kids may be admitted over the first — regardless of racial background. — lp 8. February 8, 2012 8:20 pm Link University admissions in the US are not strictly quantitative. However, for many top flight universities outside the US they still are. Try Europe or Asia and come back to the States for grad school. — Scottish Non-Golfer 9. February 8, 2012 10:41 pm Link “as a cohort, Asian-Americans have the highest SAT and ACT scores.” In the book “SAT Wars: The Case for Test-Optional College Admissions”, previously reviewed in the Choice Blog, there is a chapter by Jay Rosner which presents evidence of “serious racial and gender biases in the question selection process for the SAT” (p. 202). Might it be possible that the SAT itself is biased in favor of Asian Americans over other racial groups, and if so, is this possibility being investigated as part of the OCR’s discrimination case?<query> which racial group has the highest sat scores</query>\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pyserini.index.lucene \\\n",
        "  --collection JsonCollection \\\n",
        "  --input /content/sample_collection_jsonl \\\n",
        "  --index /content/indexes/sample_collection_jsonl \\\n",
        "  --generator DefaultLuceneDocumentGenerator \\\n",
        "  --threads 4 \\\n",
        "  --storePositions --storeDocvectors --storeRaw"
      ],
      "metadata": {
        "id": "3yX6Va35mJIz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19e8f87c-fa64-48bc-b924-c3375fb3579c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n",
            "2022-03-18 02:24:52,355 INFO  [main] index.IndexCollection (IndexCollection.java:643) - Setting log level to INFO\n",
            "2022-03-18 02:24:52,358 INFO  [main] index.IndexCollection (IndexCollection.java:646) - Starting indexer...\n",
            "2022-03-18 02:24:52,358 INFO  [main] index.IndexCollection (IndexCollection.java:647) - ============ Loading Parameters ============\n",
            "2022-03-18 02:24:52,359 INFO  [main] index.IndexCollection (IndexCollection.java:648) - DocumentCollection path: /content/sample_collection_jsonl\n",
            "2022-03-18 02:24:52,359 INFO  [main] index.IndexCollection (IndexCollection.java:649) - CollectionClass: JsonCollection\n",
            "2022-03-18 02:24:52,359 INFO  [main] index.IndexCollection (IndexCollection.java:650) - Generator: DefaultLuceneDocumentGenerator\n",
            "2022-03-18 02:24:52,360 INFO  [main] index.IndexCollection (IndexCollection.java:651) - Threads: 4\n",
            "2022-03-18 02:24:52,366 INFO  [main] index.IndexCollection (IndexCollection.java:652) - Language: en\n",
            "2022-03-18 02:24:52,367 INFO  [main] index.IndexCollection (IndexCollection.java:653) - Stemmer: porter\n",
            "2022-03-18 02:24:52,367 INFO  [main] index.IndexCollection (IndexCollection.java:654) - Keep stopwords? false\n",
            "2022-03-18 02:24:52,368 INFO  [main] index.IndexCollection (IndexCollection.java:655) - Stopwords: null\n",
            "2022-03-18 02:24:52,368 INFO  [main] index.IndexCollection (IndexCollection.java:656) - Store positions? true\n",
            "2022-03-18 02:24:52,369 INFO  [main] index.IndexCollection (IndexCollection.java:657) - Store docvectors? true\n",
            "2022-03-18 02:24:52,370 INFO  [main] index.IndexCollection (IndexCollection.java:658) - Store document \"contents\" field? false\n",
            "2022-03-18 02:24:52,371 INFO  [main] index.IndexCollection (IndexCollection.java:659) - Store document \"raw\" field? true\n",
            "2022-03-18 02:24:52,371 INFO  [main] index.IndexCollection (IndexCollection.java:660) - Optimize (merge segments)? false\n",
            "2022-03-18 02:24:52,372 INFO  [main] index.IndexCollection (IndexCollection.java:661) - Whitelist: null\n",
            "2022-03-18 02:24:52,372 INFO  [main] index.IndexCollection (IndexCollection.java:662) - Pretokenized?: false\n",
            "2022-03-18 02:24:52,373 INFO  [main] index.IndexCollection (IndexCollection.java:682) - Directly building Lucene indexes...\n",
            "2022-03-18 02:24:52,373 INFO  [main] index.IndexCollection (IndexCollection.java:683) - Index path: /content/indexes/sample_collection_jsonl\n",
            "2022-03-18 02:24:52,379 INFO  [main] index.IndexCollection (IndexCollection.java:738) - ============ Indexing Collection ============\n",
            "2022-03-18 02:24:52,667 INFO  [main] index.IndexCollection (IndexCollection.java:839) - Thread pool with 4 threads initialized.\n",
            "2022-03-18 02:24:52,668 INFO  [main] index.IndexCollection (IndexCollection.java:841) - Initializing collection in /content/sample_collection_jsonl\n",
            "2022-03-18 02:24:52,671 INFO  [main] index.IndexCollection (IndexCollection.java:850) - 1 file found\n",
            "2022-03-18 02:24:52,672 INFO  [main] index.IndexCollection (IndexCollection.java:851) - Starting to index...\n",
            "2022-03-18 02:25:52,677 INFO  [main] index.IndexCollection (IndexCollection.java:869) - 270,000 documents indexed\n",
            "2022-03-18 02:26:52,677 INFO  [main] index.IndexCollection (IndexCollection.java:869) - 530,000 documents indexed\n",
            "2022-03-18 02:27:52,683 INFO  [main] index.IndexCollection (IndexCollection.java:869) - 800,000 documents indexed\n",
            "2022-03-18 02:28:08,899 DEBUG [pool-2-thread-1] index.IndexCollection$LocalIndexerThread (IndexCollection.java:248) - sample_collection_jsonl/documents.jsonl: 868654 docs added.\n",
            "2022-03-18 02:28:33,610 INFO  [main] index.IndexCollection (IndexCollection.java:935) - Indexing Complete! 868,654 documents indexed\n",
            "2022-03-18 02:28:33,611 INFO  [main] index.IndexCollection (IndexCollection.java:936) - ============ Final Counter Values ============\n",
            "2022-03-18 02:28:33,611 INFO  [main] index.IndexCollection (IndexCollection.java:937) - indexed:          868,654\n",
            "2022-03-18 02:28:33,611 INFO  [main] index.IndexCollection (IndexCollection.java:938) - unindexable:            0\n",
            "2022-03-18 02:28:33,611 INFO  [main] index.IndexCollection (IndexCollection.java:939) - empty:                  0\n",
            "2022-03-18 02:28:33,612 INFO  [main] index.IndexCollection (IndexCollection.java:940) - skipped:                0\n",
            "2022-03-18 02:28:33,612 INFO  [main] index.IndexCollection (IndexCollection.java:941) - errors:                 0\n",
            "2022-03-18 02:28:33,620 INFO  [main] index.IndexCollection (IndexCollection.java:944) - Total 868,654 documents indexed in 00:03:41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/indexes/sample_collection_jsonl"
      ],
      "metadata": {
        "id": "DUUrPi0-mJON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47753e3c-e781-4d79-ba09-a767fdd6aa95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_0.fdm\t_0_Lucene80_0.dvd  _0_Lucene84_0.tim  _0.nvm  _0.tvx\n",
            "_0.fdt\t_0_Lucene80_0.dvm  _0_Lucene84_0.tip  _0.si   segments_1\n",
            "_0.fdx\t_0_Lucene84_0.doc  _0_Lucene84_0.tmd  _0.tvd  write.lock\n",
            "_0.fnm\t_0_Lucene84_0.pos  _0.nvd\t      _0.tvm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyserini.search.lucene import LuceneSearcher\n",
        "searcher = LuceneSearcher('indexes/sample_collection_jsonl')\n",
        "hits = searcher.search('Who is stronger, Hulk or Superman?', k=12)\n",
        "# Value of K determines the number of documents that can be returned.\n",
        "print('Number of document matches from the index: '+str(len(hits)))\n",
        "# Attempted tuning BM25 and RM3, nothing has changed the document ranking below.\n",
        "for i in range(len(hits)):\n",
        "    print(f'{i+1} {hits[i].docid} {hits[i].score:.5f}')"
      ],
      "metadata": {
        "id": "ncVg0KYTmJQY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcad1bb6-757b-4c22-939e-d3f17cd25cd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of document matches from the index: 12\n",
            "1 clueweb12-1400wb-06-30596___3 16.55650\n",
            "2 clueweb12-0605wb-29-30060___11 15.76430\n",
            "3 clueweb12-1709wb-12-07226___7 15.69540\n",
            "4 clueweb12-0605wb-29-30060___2 15.21990\n",
            "5 clueweb12-0904wb-33-14589___7 15.14270\n",
            "6 clueweb12-1400wb-06-30596___4 15.02100\n",
            "7 clueweb12-1411wb-25-14634___8 14.83110\n",
            "8 clueweb12-0605wb-29-30060___10 14.75490\n",
            "9 clueweb12-1014wb-84-07457___12 14.68790\n",
            "10 clueweb12-1400tw-67-08199___28 14.26160\n",
            "11 clueweb12-0306wb-63-29079___5 14.16490\n",
            "12 clueweb12-0605wb-57-17257___8 13.69220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab the raw text:\n",
        "print(hits[0].raw)\n",
        "print('\\n')\n",
        "# Grab the raw Lucene Document:\n",
        "print(hits[0].lucene_document)"
      ],
      "metadata": {
        "id": "7q1vTs9KmJfO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aa1937e-e3dc-44e2-bff3-78bf82a25e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\" : \"clueweb12-1400wb-06-30596___3\",\n",
            "  \"contents\" : \"There is a limit to how angry someone gets...even the Hulk and even at his angriest he wouldn't be as strong as Superman. No one really knows how strong the man of steel is and perhaps neither does he! Many wrongly think that just because Hulk is bigger and looks stronger than it means he is stronger. Superman can move planets...need I say more! Others believe Hulk would win because they're likely Marvel fan boys. Superman has defeated powerful opponents like Darkseid,Mongrel,Parasite,Doomsday,and General Zod;several of whom could likely take Hulk! Superman has more varied powers and because he's smarter can be more resourceful in using them. Speaking of intelligence,how the hell can anyone think that Superman isn't smarter than a human,even one as brilliant as Dr.Bruce Banner. Superman/Kal-El is not only the son of Jor-El,Krypton's most brilliant scientist,but he's outsmarted Lex Luthor(one of the smartest people on earth)and Brainiac(the smartest artificial being ever created)so yes I think he's smarter than Banner.<query> who is stronger superman or hulk</query>\"\n",
            "}\n",
            "\n",
            "\n",
            "<org.apache.lucene.document.Document at 0x7f81f67ca0b0 jclass=org/apache/lucene/document/Document jself=<LocalRef obj=0x56214d597ed0 at 0x7f81ac6eef90>>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building Dense Index, GPU activated for building dense index.\n",
        "# This index is build to do \"Dense\" and \"Sparse\" retrieval from documents."
      ],
      "metadata": {
        "id": "ZuskMg_IAJl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir indexes/sample_collection_jsonl_dense"
      ],
      "metadata": {
        "id": "7JJL7WiG45uX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding documents with dense encoder representations\n",
        "# Expected time was showing around 15 hours\n",
        "# Sample execution is checked, but this should be prepared after more analysis.\n",
        "# Colab Pro, is definitely required for preparing the dense representations.\n",
        "# Sharding approach doesn't execute indexes in parallel. Hence, only shard num = 1 allowed.\n",
        "!python -m pyserini.encode input --corpus /content/sample_collection_jsonl \\\n",
        "          --fields text \\\n",
        "          --delimiter \"\\n\" \\\n",
        "          --shard-id 0 \\\n",
        "          --shard-num 1 \\\n",
        "  output  --embeddings /content/indexes/sample_collection_jsonl_dense \\\n",
        "          --to-faiss \\\n",
        "  encoder --encoder castorini/tct_colbert-v2-hnp-msmarco \\\n",
        "          --fields text \\\n",
        "          --batch 32 \\\n",
        "          --fp16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NulfbYJw3ZC_",
        "outputId": "1ba6d478-c50e-48fe-d007-a637632fce7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "868654it [00:08, 99470.32it/s]\n",
            "  0% 16/13573 [00:45<10:36:15,  2.82s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pyserini/encode/__main__.py\", line 103, in <module>\n",
            "    embeddings = encoder.encode(**kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pyserini/encode/_tct_colbert.py\", line 66, in encode\n",
            "    outputs = self.model(**inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\", line 1006, in forward\n",
            "    return_dict=return_dict,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\", line 592, in forward\n",
            "    output_attentions,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\", line 477, in forward\n",
            "    past_key_value=self_attn_past_key_value,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\", line 409, in forward\n",
            "    output_attentions,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\", line 306, in forward\n",
            "    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding attempt with sparse encoder\n",
        "# Expected time for completion is even more for these encoders.\n",
        "!python -m pyserini.encode \\\n",
        "  input   --corpus /content/sample_collection_jsonl \\\n",
        "          --fields text \\\n",
        "  output  --embeddings /content/indexes/sample_collection_jsonl_dense \\\n",
        "  encoder --encoder castorini/unicoil-msmarco-passage \\\n",
        "          --fields text \\\n",
        "          --batch 32 \\\n",
        "          --fp16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vxF9hvm3ZIA",
        "outputId": "caeae359-7cd6-4a08-9d65-2353a128d383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: 100% 677/677 [00:00<00:00, 1.01MB/s]\n",
            "Downloading: 100% 418M/418M [00:12<00:00, 35.9MB/s]\n",
            "Downloading: 100% 226k/226k [00:00<00:00, 1.99MB/s]\n",
            "Downloading: 100% 112/112 [00:00<00:00, 95.2kB/s]\n",
            "Downloading: 100% 300/300 [00:00<00:00, 311kB/s]\n",
            "868654it [00:09, 92140.35it/s]\n",
            "  0% 7/27146 [00:25<27:01:00,  3.58s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pyserini/encode/__main__.py\", line 103, in <module>\n",
            "    embeddings = encoder.encode(**kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pyserini/encode/_unicoil.py\", line 96, in encode\n",
            "    batch_weights = self.model(input_ids).cpu().detach().numpy()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pyserini/encode/_unicoil.py\", line 69, in forward\n",
            "    outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\", line 1006, in forward\n",
            "    return_dict=return_dict,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\", line 592, in forward\n",
            "    output_attentions,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\", line 477, in forward\n",
            "    past_key_value=self_attn_past_key_value,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\", line 409, in forward\n",
            "    output_attentions,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\", line 340, in forward\n",
            "    context_layer = torch.matmul(attention_probs, value_layer)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally, converting it into HNSW index for retrieval.\n",
        "# Getting Dense and Hybrid retrieval results, code available in README.md"
      ],
      "metadata": {
        "id": "NzpKykoU3ZKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ovy6r72QnxE2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}