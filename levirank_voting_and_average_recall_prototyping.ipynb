{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "levirank-voting-and-average-recall-prototyping.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D4j85Y-nmGV7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "543e7f3e-f2a6-4f37-a7c2-8d6052cf87c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# TASK 1: Comparative Performance analysis for Voting based and Baseline LeviRank retrieval.\n",
        "# 1. Building the voting based ranking and calculating average recall/coverage metric.\n",
        "# 2.  Building the baseline ranking and calculating average recall/coverage metric.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cleaning sample_data directory.\n",
        "!rm -r sample_data"
      ],
      "metadata": {
        "id": "Hj7M-YF9A3n5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the list of files that are present in the pwd.\n",
        "!ls drive/My\\ Drive/touche-2022-prototyping"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxPrdX68Auuf",
        "outputId": "4740866c-9d83-443b-c4b8-55fdc7d35852"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "contrastive-learning-retrieval-comparison-pipeline.ipynb\n",
            "dataset-prep-and-retrieval-diagnostic-analysis.ipynb\n",
            "document_embeddings.pickle\n",
            "indexes\n",
            "initial-retrieval-metric-analysis.ipynb\n",
            "levirank-voting-and-average-recall-prototyping.ipynb\n",
            "missed_1000.csv\n",
            "missed_1200.csv\n",
            "missed_1375.csv\n",
            "missed_1500.csv\n",
            "missed_250.csv\n",
            "missed_500.csv\n",
            "missed_786.csv\n",
            "missed_full_1000.csv\n",
            "missed_full_1375.csv\n",
            "missed_full_1500.csv\n",
            "missed_full_250.csv\n",
            "missed_full_500.csv\n",
            "missed_full_786.csv\n",
            "mon-duo-retrieval-prototyping-and-analysis.ipynb\n",
            "topic_embeddings.pickle\n",
            "topics-task2-51-100.xml\n",
            "topics-task-2.xml\n",
            "touche2020-task2-relevance-withbaseline.qrels\n",
            "touche_complete_topics.csv\n",
            "touche_ground_truth.csv\n",
            "touche_results_2021.csv\n",
            "touche-task2-51-100-relevance.qrels\n",
            "touche-task2-passages-version-002-expanded-with-doc-t5-query.jsonl\n",
            "touche_topics_query_expansion.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import statements, must required for the final script.\n",
        "import logging\n",
        "import tarfile\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet\n",
        "import spacy\n",
        "import string\n",
        "from tqdm import tqdm\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "random.seed(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdl_5nBbLDPF",
        "outputId": "e0a71f2c-dcd2-4e37-b36c-f25f9011ed68"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing spacy working & all, that's it!\n",
        "# one-time pre-loading of libraries for word vectorization.\n",
        "# Not required for the final script, only testing purpose.\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "sp = spacy.load(\"en_core_web_sm\")\n",
        "all_stopwords = sp.Defaults.stop_words"
      ],
      "metadata": {
        "id": "UNS53XfyC5Ao"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample test, not required to be added into the final script.\n",
        "text = sp(\"Nick likes to play football, however he is not too fond of tennis.\")\n",
        "# text_tokens = word_tokenize(text)\n",
        "# print(text\n",
        "#       )\n",
        "token_list = []\n",
        "token_tag_list = []\n",
        "for token in text:\n",
        "    token_list.append(token.text)\n",
        "    token_tag_list.append(token.tag_)\n",
        "print(token_list)\n",
        "print(token_tag_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmQ63ftrYiu1",
        "outputId": "b1b980c9-a4e4-45da-d595-a63d4d478866"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Nick', 'likes', 'to', 'play', 'football', ',', 'however', 'he', 'is', 'not', 'too', 'fond', 'of', 'tennis', '.']\n",
            "['NNP', 'VBZ', 'TO', 'VB', 'NN', ',', 'RB', 'PRP', 'VBZ', 'RB', 'RB', 'JJ', 'IN', 'NN', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# important function, required to be implemented in the query expansion script.\n",
        "# extracts list of synonyms and antonyms from the wordnet.\n",
        "def synonym_antonym_extractor(w_):\n",
        "     # extracting relevant synonyms and antonym pairs.\n",
        "     from nltk.corpus import wordnet\n",
        "     synonyms = []\n",
        "     antonyms = []\n",
        "\n",
        "     for syn in wordnet.synsets(w_):\n",
        "          for l in syn.lemmas():\n",
        "               synonyms.append(str(l.name()).replace('_',' '))\n",
        "               if l.antonyms():\n",
        "                    antonyms.append(str(l.antonyms()[0].name()).replace('_',' '))\n",
        "     return list(set(synonyms)), list(set(antonyms))\n",
        "# synonym_antonym_extractor('better')"
      ],
      "metadata": {
        "id": "VS1QjpUEaj0r"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Must required and embeddings to be downloaded into the script.\n",
        "# import statements and GloVe embeddings loading for word vectorization.\n",
        "import gensim.downloader as api\n",
        "# overview of all models in gensim: https://github.com/RaRe-Technologies/gensim-data\n",
        "model_glove = api.load(\"glove-wiki-gigaword-300\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRi_1pWiawoB",
        "outputId": "7a1959af-36b9-4ca1-a44f-1539c6094eb9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Important function required for the script you are making, for extract best\n",
        "# synonym and antonym words. Second, it also calls synonym_antonym_extractor function in it.\n",
        "# Also, it requires above loading of the module for its working.\n",
        "\n",
        "# Getting 3 best synonyms and 2 best antonym pairs for a given 'ADJ'\n",
        "def best_words_extractor(w_, syn_list, ann_list):\n",
        "    # prepare dictionaries for scores of syn_list & ann_list with w_\n",
        "    syns = []\n",
        "    anns = []\n",
        "    for s_ in syn_list:\n",
        "        try:\n",
        "            if model_glove.get_vector(s_) is not None and s_ != w_:\n",
        "                syns.append(s_)\n",
        "        except:\n",
        "            pass\n",
        "    # print(syns)\n",
        "    for a_ in ann_list:\n",
        "        try:\n",
        "            if model_glove.get_vector(a_) is not None and a_ != w_:\n",
        "                anns.append(a_)\n",
        "        except:\n",
        "            pass\n",
        "    # print(anns)\n",
        "    syn_score_dict = {}\n",
        "    ann_score_dict = {}\n",
        "    for s_ in syns:\n",
        "        syn_score_dict[s_] = model_glove.distance(w_, s_)\n",
        "    for a_ in anns:\n",
        "        ann_score_dict[a_] = model_glove.distance(w_, a_)\n",
        "    # getting only the top-k most similar synonyms and most dissimilar antonyms\n",
        "    # values from the dictionaries and creating score permutations for them.\n",
        "    syn_score_dict = {k: v for k, v in sorted(syn_score_dict.items(), key=lambda item: item[1])}\n",
        "    # print(syn_score_dict)\n",
        "    syn_score_dict = {k: syn_score_dict[k] for k in list(syn_score_dict)[:20]}\n",
        "    # print(syn_score_dict)\n",
        "    ann_score_dict = {k: v for k, v in sorted(ann_score_dict.items(), key=lambda item: item[1])}\n",
        "    # print(ann_score_dict)\n",
        "    ann_score_dict = {k: ann_score_dict[k] for k in list(ann_score_dict)[:20]}\n",
        "    # print(ann_score_dict)\n",
        "    syn_data = []\n",
        "    ann_data = []\n",
        "    c_ = 0\n",
        "    for i, j in syn_score_dict.items():\n",
        "        c_ = c_ + 1\n",
        "        syn_data.append(i)\n",
        "        if c_ >=3:\n",
        "            break\n",
        "    if len(syn_data) < 3:\n",
        "        syn_data = ['good','well', 'best']\n",
        "    c_ = 0\n",
        "    for i, j in ann_score_dict.items():\n",
        "        c_ = c_ + 1\n",
        "        ann_data.append(i)\n",
        "        if c_ >=1:\n",
        "            break\n",
        "    if len(ann_data) < 2:\n",
        "        if len(ann_data) == 0:\n",
        "            ann_data = ['worse','badly']\n",
        "        if len(ann_data) == 1 and ann_data[0] != 'worse':\n",
        "            ann_data.append('worse')\n",
        "        if len(ann_data) == 1 and ann_data[0] == 'worse':\n",
        "            ann_data.append('different')\n",
        "    return syn_data, ann_data "
      ],
      "metadata": {
        "id": "YMZP8OQHazAb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing the outputs for above defined functions.\n",
        "# specifically, 'synonym_antonym_extractor' and 'best_words_extractor' \n",
        "syns, anons = synonym_antonym_extractor('better')\n",
        "print(syns)\n",
        "print(anons)\n",
        "print(best_words_extractor('better', syns, anons))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zDKRaSXazli",
        "outputId": "6bcb9d41-7457-4463-ad67-26e7748375c3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['improve', 'in effect', 'easily', 'unspoilt', 'punter', 'bettor', 'best', 'right', 'sound', 'practiced', 'break', 'honorable', 'proficient', 'skilful', 'undecomposed', 'secure', 'amend', 'substantially', 'wagerer', 'intimately', 'in force', 'ameliorate', 'well', 'meliorate', 'good', 'upright', 'better', 'dear', 'full', 'effective', 'serious', 'ripe', 'advantageously', 'respectable', 'salutary', 'dependable', 'honest', 'safe', 'just', 'unspoiled', 'beneficial', 'adept', 'skillful', 'near', 'considerably', 'comfortably', 'estimable', 'expert']\n",
            "['worsen', 'badly', 'ill', 'worse', 'evil', 'bad', 'disadvantageously']\n",
            "(['good', 'well', 'improve'], ['worse', 'different'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTANT: This function combined with above two synonym and antonym\n",
        "# finding and generating function is required to generate the expanded queries.\n",
        "# return two expanded query versions.\n",
        "# nouns only, top-3 synonyms and antonyms queries.\n",
        "# Note: this is the final function that given an input query generates out\n",
        "# series of various expanded queries as output.\n",
        "def get_comparation_superlation_nouns(query):\n",
        "    nouns_as_string = []\n",
        "    nouns_only_string = []\n",
        "    restricted_nouns_as_string = []\n",
        "    doc = sp(query)\n",
        "    annotations = [\"CC\", \"CD\", \"JJ\", \"JJR\", \"JJS\",\n",
        "            \"RB\", \"RBR\", \"RBS\", \"NN\", \"NNS\", \"NNP\",\n",
        "            \"NNPS\", \"VB\"]\n",
        "    annotations_except_nouns = [\"CC\", \"CD\", \"JJ\", \"JJR\", \"JJS\",\n",
        "            \"RB\", \"RBR\", \"RBS\", \"VB\"]\n",
        "    annotations_nouns = [\"NN\", \"NNS\", \"NNP\", \"NNPS\", \"VB\"]\n",
        "    adj_flg = 0\n",
        "    adj_val = 'better' # default value, query objectives.\n",
        "    # appending data into nouns as string\n",
        "    for token in doc:\n",
        "        if token.tag_ in annotations:\n",
        "            nouns_as_string.append(token.text)\n",
        "            if token.tag_ in annotations_except_nouns and adj_flg == 0:\n",
        "                adj_val = token.text\n",
        "                adj_flg = 1\n",
        "            if token.tag_ not in annotations_except_nouns:\n",
        "                restricted_nouns_as_string.append(token.text)\n",
        "            if token.tag_ in annotations_nouns:\n",
        "                nouns_only_string.append(token.text)\n",
        "\n",
        "    # appending top-3 syns and anons to the query\n",
        "    adj_val= adj_val.lower()\n",
        "    syns, anons = synonym_antonym_extractor(adj_val)\n",
        "    # print(syns, anons)\n",
        "    if len(syns) == 0:\n",
        "        syns, _ = synonym_antonym_extractor('different')\n",
        "    if len(anons) == 0:\n",
        "        _, anons = synonym_antonym_extractor('better')\n",
        "    \n",
        "    syns_fin, anons_fin = best_words_extractor(adj_val,syns, anons)\n",
        "    \n",
        "    # queries preprepartion\n",
        "    base_query = \" \".join(nouns_as_string)\n",
        "    noun_query = \" \".join(nouns_only_string)\n",
        "    temp_query = \" \".join(restricted_nouns_as_string)\n",
        "    syn1_query = \"\".join(syns_fin[0]).strip() + \" \" + temp_query\n",
        "    syn2_query = \"\".join(syns_fin[1]).strip() + \" \" + temp_query\n",
        "    syn3_query = \"\".join(syns_fin[2]).strip() + \" \" + temp_query\n",
        "    ant1_query = \"\".join(anons_fin[0]).strip() + \" \" + temp_query\n",
        "    ant2_query = \"\".join(anons_fin[1]).strip() + \" \" + temp_query\n",
        "\n",
        "    return base_query.strip(), noun_query.strip(), syn1_query.strip(), syn2_query.strip(), syn3_query.strip(), \\\n",
        "    ant1_query.strip(), ant2_query.strip()"
      ],
      "metadata": {
        "id": "ld3TbpPULC_M"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample example for testing out the function.\n",
        "topics = [\n",
        "    \"What is the difference between sex and love?\",\n",
        "    \"Which is the highest mountain in the world?\",\n",
        "    \"Which is better, a laptop or a desktop?\",\n",
        "]\n",
        "for q in topics:\n",
        "    print(get_comparation_superlation_nouns(q))\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zo68aON7LC6c",
        "outputId": "c1474167-5d1b-40d4-c2e7-d37463178339"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('difference sex and love', 'difference sex love', 'different difference sex love', 'unlike difference sex love', 'dissimilar difference sex love', 'bad difference sex love', 'worse difference sex love')\n",
            "\n",
            "\n",
            "('highest mountain world', 'mountain world', 'high mountain world', 'eminent mountain world', 'high-pitched mountain world', 'low mountain world', 'worse mountain world')\n",
            "\n",
            "\n",
            "('better laptop or desktop', 'laptop desktop', 'good laptop desktop', 'well laptop desktop', 'improve laptop desktop', 'worse laptop desktop', 'different laptop desktop')\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extensive sample testing example for getting out the function results.\n",
        "topics_large = [\n",
        "    \"What is the difference between sex and love?\",\n",
        "    \"Which is better, a laptop or a desktop?\",\n",
        "    \"Which is better, Canon or Nikon?\",\n",
        "    \"What are the best dish detergents?\",\n",
        "    \"What are the best cities to live in?\",\n",
        "    \"What is the longest river in the U.S.?\",\n",
        "    \"Which is healthiest: coffee, green tea or black tea and why?\",\n",
        "    \"What are the advantages and disadvantages of PHP over Python and vice versa?\",\n",
        "    \"Why is Linux better than Windows?\",\n",
        "    \"How to sleep better?\",\n",
        "    \"Should I buy an LCD TV or a plasma TV?\",\n",
        "    \"Train or plane? Which is the better choice?\",\n",
        "    \"What is the highest mountain on Earth?\",\n",
        "    \"Should one prefer Chinese medicine or Western medicine?\",\n",
        "    \"What are the best washing machine brands?\",\n",
        "    \"Should I buy or rent?\",\n",
        "    \"Do you prefer cats or dogs, and why?\",\n",
        "    \"What is the better way to grill outdoors: gas or charcoal?\",\n",
        "    \"Which is better, MAC or PC?\",\n",
        "    \"What is better: to use a brush or a sponge?\",\n",
        "    \"Which is better, Linux or Microsoft?\",\n",
        "    \"Which is better, Pepsi or Coke?\",\n",
        "    \"What is better, Google search or Yahoo search?\",\n",
        "    \"Which one is better, Netflix or Blockbuster?\",\n",
        "    \"Which browser is better, Internet Explorer or Firefox?\",\n",
        "    \"Which is a better vehicle: BMW or Audi?\",\n",
        "    \"Which one is better, an electric stove or a gas stove?\",\n",
        "    \"What planes are best, Boeing or Airbus?\",\n",
        "    \"Which is better, Disneyland or Disney World?\",\n",
        "    \"Should I buy an Xbox or a PlayStation?\",\n",
        "    \"Which has more caffeine, coffee or tea?\",\n",
        "    \"Which is better, LED or LCD Reception Displays?\",\n",
        "    \"What is better: ASP or PHP?\",\n",
        "    \"What is better for the environment, a real or a fake Christmas tree?\",\n",
        "    \"Do you prefer tampons or pads?\",\n",
        "    \"What IDE is better for Java: NetBeans or Eclipse?\",\n",
        "    \"Is OpenGL better than Direct3D in terms of portability to different platforms?\",\n",
        "    \"What are the differences between MySQL and PostgreSQL in performance?\",\n",
        "    \"Is Java code more readable than code written in Scala?\",\n",
        "    \"Which operating system has better performance: Windows 7 or Windows 8?\",\n",
        "    \"Which smartphone has a better battery life: Xperia or iPhone?\",\n",
        "    \"Which four wheel truck is better: Ford or Toyota?\",\n",
        "    \"Should I prefer a Leica camera over Nikon for portrait photographs?\",\n",
        "    \"Which company has a larger capitalization: Apple or Microsoft?\",\n",
        "    \"Which laptop has a better durability: HP or Dell?\",\n",
        "    \"Which beverage has more calories per glass: beer or cider?\",\n",
        "    \"Is admission rate in Stanford higher than that of MIT?\",\n",
        "    \"Is pasta healthier than pizza?\",\n",
        "    \"Which city is more expensive to live in: San Francisco or New York?\",\n",
        "    \"Whose salary is higher: basketball or soccer players?\",\n",
        "]\n",
        "for q in topics_large:\n",
        "    print(get_comparation_superlation_nouns(q))\n",
        "    print('\\n')"
      ],
      "metadata": {
        "id": "-Bbap5u9LC4K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7633bee-a4a8-4a17-f9d7-1e47778a8e57"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('difference sex and love', 'difference sex love', 'different difference sex love', 'unlike difference sex love', 'dissimilar difference sex love', 'bad difference sex love', 'worse difference sex love')\n",
            "\n",
            "\n",
            "('better laptop or desktop', 'laptop desktop', 'good laptop desktop', 'well laptop desktop', 'improve laptop desktop', 'worse laptop desktop', 'different laptop desktop')\n",
            "\n",
            "\n",
            "('better Canon or Nikon', 'Canon Nikon', 'good Canon Nikon', 'well Canon Nikon', 'improve Canon Nikon', 'worse Canon Nikon', 'different Canon Nikon')\n",
            "\n",
            "\n",
            "('best dish detergents', 'detergents', 'better detergents', 'good detergents', 'well detergents', 'worst detergents', 'worse detergents')\n",
            "\n",
            "\n",
            "('best cities live', 'cities live', 'better cities', 'good cities', 'well cities', 'worst cities', 'worse cities')\n",
            "\n",
            "\n",
            "('longest river U.S.', 'river U.S.', 'long river U.S.', 'tenacious river U.S.', 'retentive river U.S.', 'short river U.S.', 'worse river U.S.')\n",
            "\n",
            "\n",
            "('healthiest coffee green tea or black tea and', 'coffee tea tea', 'healthy coffee tea tea', 'levelheaded coffee tea tea', 'level-headed coffee tea tea', 'unhealthy coffee tea tea', 'worse coffee tea tea')\n",
            "\n",
            "\n",
            "('advantages and disadvantages PHP Python and vice versa', 'advantages disadvantages PHP Python vice', 'different advantages disadvantages PHP Python vice', 'unlike advantages disadvantages PHP Python vice', 'dissimilar advantages disadvantages PHP Python vice', 'bad advantages disadvantages PHP Python vice', 'worse advantages disadvantages PHP Python vice')\n",
            "\n",
            "\n",
            "('Linux better Windows', 'Linux Windows', 'good Linux Windows', 'well Linux Windows', 'improve Linux Windows', 'worse Linux Windows', 'different Linux Windows')\n",
            "\n",
            "\n",
            "('sleep better', 'sleep', 'nap', 'rest', 'slumber', 'wake', 'worse')\n",
            "\n",
            "\n",
            "('buy LCD TV or plasma TV', 'buy LCD TV plasma TV', 'purchase LCD TV plasma TV', 'steal LCD TV plasma TV', 'bargain LCD TV plasma TV', 'sell LCD TV plasma TV', 'worse LCD TV plasma TV')\n",
            "\n",
            "\n",
            "('Train or plane better choice', 'Train plane choice', 'good Train plane choice', 'well Train plane choice', 'best Train plane choice', 'bad Train plane choice', 'worse Train plane choice')\n",
            "\n",
            "\n",
            "('highest mountain Earth', 'mountain Earth', 'high mountain Earth', 'eminent mountain Earth', 'high-pitched mountain Earth', 'low mountain Earth', 'worse mountain Earth')\n",
            "\n",
            "\n",
            "('prefer Chinese medicine or Western medicine', 'prefer medicine medicine', 'choose medicine medicine', 'opt medicine medicine', 'favor medicine medicine', 'worse medicine medicine', 'different medicine medicine')\n",
            "\n",
            "\n",
            "('best washing machine brands', 'washing machine brands', 'better washing machine brands', 'good washing machine brands', 'well washing machine brands', 'worst washing machine brands', 'worse washing machine brands')\n",
            "\n",
            "\n",
            "('buy or rent', 'buy rent', 'purchase', 'steal', 'bargain', 'sell', 'worse')\n",
            "\n",
            "\n",
            "('prefer cats or dogs and', 'prefer cats dogs', 'choose cats dogs', 'opt cats dogs', 'favor cats dogs', 'worse cats dogs', 'different cats dogs')\n",
            "\n",
            "\n",
            "('better way grill outdoors gas or charcoal', 'way grill gas charcoal', 'good way gas charcoal', 'well way gas charcoal', 'improve way gas charcoal', 'worse way gas charcoal', 'different way gas charcoal')\n",
            "\n",
            "\n",
            "('better MAC or PC', 'MAC PC', 'good MAC PC', 'well MAC PC', 'improve MAC PC', 'worse MAC PC', 'different MAC PC')\n",
            "\n",
            "\n",
            "('better use brush or sponge', 'use brush sponge', 'good brush sponge', 'well brush sponge', 'improve brush sponge', 'worse brush sponge', 'different brush sponge')\n",
            "\n",
            "\n",
            "('better Linux or Microsoft', 'Linux Microsoft', 'good Linux Microsoft', 'well Linux Microsoft', 'improve Linux Microsoft', 'worse Linux Microsoft', 'different Linux Microsoft')\n",
            "\n",
            "\n",
            "('better Pepsi or Coke', 'Pepsi Coke', 'good Pepsi Coke', 'well Pepsi Coke', 'improve Pepsi Coke', 'worse Pepsi Coke', 'different Pepsi Coke')\n",
            "\n",
            "\n",
            "('better Google search or Yahoo search', 'Google search Yahoo search', 'good Google search Yahoo search', 'well Google search Yahoo search', 'improve Google search Yahoo search', 'worse Google search Yahoo search', 'different Google search Yahoo search')\n",
            "\n",
            "\n",
            "('one better Netflix or Blockbuster', 'one Netflix Blockbuster', 'good one Netflix Blockbuster', 'well one Netflix Blockbuster', 'improve one Netflix Blockbuster', 'worse one Netflix Blockbuster', 'different one Netflix Blockbuster')\n",
            "\n",
            "\n",
            "('browser better Internet Explorer or Firefox', 'browser Internet Explorer Firefox', 'good browser Internet Explorer Firefox', 'well browser Internet Explorer Firefox', 'improve browser Internet Explorer Firefox', 'worse browser Internet Explorer Firefox', 'different browser Internet Explorer Firefox')\n",
            "\n",
            "\n",
            "('better vehicle BMW or Audi', 'vehicle BMW Audi', 'good vehicle BMW Audi', 'well vehicle BMW Audi', 'improve vehicle BMW Audi', 'worse vehicle BMW Audi', 'different vehicle BMW Audi')\n",
            "\n",
            "\n",
            "('one better electric stove or gas stove', 'one stove gas stove', 'good one stove gas stove', 'well one stove gas stove', 'improve one stove gas stove', 'worse one stove gas stove', 'different one stove gas stove')\n",
            "\n",
            "\n",
            "('planes best Boeing or Airbus', 'planes Boeing Airbus', 'better planes Boeing Airbus', 'good planes Boeing Airbus', 'well planes Boeing Airbus', 'worst planes Boeing Airbus', 'worse planes Boeing Airbus')\n",
            "\n",
            "\n",
            "('better Disneyland or Disney World', 'Disneyland Disney World', 'good Disneyland Disney World', 'well Disneyland Disney World', 'improve Disneyland Disney World', 'worse Disneyland Disney World', 'different Disneyland Disney World')\n",
            "\n",
            "\n",
            "('buy Xbox or PlayStation', 'buy Xbox PlayStation', 'purchase Xbox PlayStation', 'steal Xbox PlayStation', 'bargain Xbox PlayStation', 'sell Xbox PlayStation', 'worse Xbox PlayStation')\n",
            "\n",
            "\n",
            "('more caffeine coffee or tea', 'caffeine coffee tea', 'good caffeine coffee tea', 'well caffeine coffee tea', 'best caffeine coffee tea', 'less caffeine coffee tea', 'worse caffeine coffee tea')\n",
            "\n",
            "\n",
            "('better LED or LCD Reception Displays', 'LED LCD Reception Displays', 'good LED LCD Reception Displays', 'well LED LCD Reception Displays', 'improve LED LCD Reception Displays', 'worse LED LCD Reception Displays', 'different LED LCD Reception Displays')\n",
            "\n",
            "\n",
            "('better ASP or PHP', 'ASP PHP', 'good ASP PHP', 'well ASP PHP', 'improve ASP PHP', 'worse ASP PHP', 'different ASP PHP')\n",
            "\n",
            "\n",
            "('better environment real or fake Christmas tree', 'environment Christmas tree', 'good environment Christmas tree', 'well environment Christmas tree', 'improve environment Christmas tree', 'worse environment Christmas tree', 'different environment Christmas tree')\n",
            "\n",
            "\n",
            "('prefer tampons or pads', 'prefer tampons pads', 'choose tampons pads', 'opt tampons pads', 'favor tampons pads', 'worse tampons pads', 'different tampons pads')\n",
            "\n",
            "\n",
            "('IDE better Java NetBeans or Eclipse', 'IDE Java NetBeans Eclipse', 'good IDE Java NetBeans Eclipse', 'well IDE Java NetBeans Eclipse', 'improve IDE Java NetBeans Eclipse', 'worse IDE Java NetBeans Eclipse', 'different IDE Java NetBeans Eclipse')\n",
            "\n",
            "\n",
            "('OpenGL better terms portability different platforms', 'OpenGL terms portability platforms', 'good OpenGL terms portability platforms', 'well OpenGL terms portability platforms', 'improve OpenGL terms portability platforms', 'worse OpenGL terms portability platforms', 'different OpenGL terms portability platforms')\n",
            "\n",
            "\n",
            "('differences MySQL and PostgreSQL performance', 'differences MySQL PostgreSQL performance', 'different differences MySQL PostgreSQL performance', 'unlike differences MySQL PostgreSQL performance', 'dissimilar differences MySQL PostgreSQL performance', 'bad differences MySQL PostgreSQL performance', 'worse differences MySQL PostgreSQL performance')\n",
            "\n",
            "\n",
            "('Java code more readable code Scala', 'Java code code Scala', 'good Java code code Scala', 'well Java code code Scala', 'best Java code code Scala', 'less Java code code Scala', 'worse Java code code Scala')\n",
            "\n",
            "\n",
            "('system better performance Windows 7 or Windows 8', 'system performance Windows Windows', 'good system performance Windows Windows', 'well system performance Windows Windows', 'improve system performance Windows Windows', 'worse system performance Windows Windows', 'different system performance Windows Windows')\n",
            "\n",
            "\n",
            "('smartphone better battery life Xperia or iPhone', 'smartphone battery life Xperia iPhone', 'good smartphone battery life Xperia iPhone', 'well smartphone battery life Xperia iPhone', 'improve smartphone battery life Xperia iPhone', 'worse smartphone battery life Xperia iPhone', 'different smartphone battery life Xperia iPhone')\n",
            "\n",
            "\n",
            "('four wheel truck better Ford or Toyota', 'wheel truck Ford Toyota', '4 wheel truck Ford Toyota', 'quartet wheel truck Ford Toyota', 'iv wheel truck Ford Toyota', 'badly wheel truck Ford Toyota', 'worse wheel truck Ford Toyota')\n",
            "\n",
            "\n",
            "('prefer Leica camera Nikon portrait photographs', 'prefer Leica camera Nikon portrait photographs', 'choose Leica camera Nikon portrait photographs', 'opt Leica camera Nikon portrait photographs', 'favor Leica camera Nikon portrait photographs', 'worse Leica camera Nikon portrait photographs', 'different Leica camera Nikon portrait photographs')\n",
            "\n",
            "\n",
            "('company larger capitalization Apple or Microsoft', 'company capitalization Apple Microsoft', 'bigger company capitalization Apple Microsoft', 'large company capitalization Apple Microsoft', 'big company capitalization Apple Microsoft', 'small company capitalization Apple Microsoft', 'worse company capitalization Apple Microsoft')\n",
            "\n",
            "\n",
            "('laptop better durability HP or Dell', 'laptop durability HP Dell', 'good laptop durability HP Dell', 'well laptop durability HP Dell', 'improve laptop durability HP Dell', 'worse laptop durability HP Dell', 'different laptop durability HP Dell')\n",
            "\n",
            "\n",
            "('beverage more calories glass beer or cider', 'beverage calories glass beer cider', 'good beverage calories glass beer cider', 'well beverage calories glass beer cider', 'best beverage calories glass beer cider', 'less beverage calories glass beer cider', 'worse beverage calories glass beer cider')\n",
            "\n",
            "\n",
            "('admission rate Stanford higher MIT', 'admission rate Stanford MIT', 'high admission rate Stanford MIT', 'eminent admission rate Stanford MIT', 'mellow admission rate Stanford MIT', 'low admission rate Stanford MIT', 'worse admission rate Stanford MIT')\n",
            "\n",
            "\n",
            "('pasta healthier pizza', 'pasta pizza', 'healthy pasta pizza', 'fitter pasta pizza', 'salubrious pasta pizza', 'unhealthy pasta pizza', 'worse pasta pizza')\n",
            "\n",
            "\n",
            "('city more expensive live San Francisco or New York', 'city live San Francisco New York', 'good city San Francisco New York', 'well city San Francisco New York', 'best city San Francisco New York', 'less city San Francisco New York', 'worse city San Francisco New York')\n",
            "\n",
            "\n",
            "('salary higher basketball or soccer players', 'salary basketball soccer players', 'high salary basketball soccer players', 'eminent salary basketball soccer players', 'mellow salary basketball soccer players', 'low salary basketball soccer players', 'worse salary basketball soccer players')\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not required for building your script, it's used hear for testing baseline\n",
        "# and voting based query expansion methods.\n",
        "from xml.dom import minidom\n",
        "# define function for loading all the topics from the topics files.\n",
        "def parse_xml(path):\n",
        "  answer_list = []\n",
        "  xmldoc = minidom.parse(path)\n",
        "  itemlist = xmldoc.getElementsByTagName('topics')\n",
        "  topic_list = itemlist[0].getElementsByTagName('topic')\n",
        "  for topic in topic_list:\n",
        "    tuple_for_add = tuple((topic.getElementsByTagName('number')[0].firstChild.nodeValue, topic.getElementsByTagName('title')[0].firstChild.nodeValue))\n",
        "    answer_list.append(tuple_for_add)\n",
        "  parsed=pd.DataFrame(answer_list, columns=[\"number\",\"title\"])\n",
        "  return parsed\n",
        "\n",
        "# preparing the list of topics and corresponding dataframe.\n",
        "topics_2020 = parse_xml(\"/content/drive/MyDrive/touche-2022-prototyping/topics-task-2.xml\")\n",
        "topics_2021 = parse_xml(\"/content/drive/MyDrive/touche-2022-prototyping/topics-task2-51-100.xml\")\n",
        "touche_topics = topics_2020.append(topics_2021, ignore_index=True)\n",
        "touche_topics"
      ],
      "metadata": {
        "id": "yZF3geRALCyu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "00ff81b6-83dd-4e19-c71e-61c790c9390d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   number                                              title\n",
              "0       1   \\nWhat is the difference between sex and love?\\n\n",
              "1       2        \\nWhich is better, a laptop or a desktop?\\n\n",
              "2       3               \\nWhich is better, Canon or Nikon?\\n\n",
              "3       4             \\nWhat are the best dish detergents?\\n\n",
              "4       5           \\nWhat are the best cities to live in?\\n\n",
              "..    ...                                                ...\n",
              "95     96      Which is healthier to wear, boxers or briefs?\n",
              "96     97  What is the difference between a blender vs a ...\n",
              "97     98                      Which is better, rock or rap?\n",
              "98     99  Do you think imagination is better than knowle...\n",
              "99    100      Should I learn Python or R for data analysis?\n",
              "\n",
              "[100 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f561fe8-ce24-44f2-b4df-57ebec39e9f3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>\\nWhat is the difference between sex and love?\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>\\nWhich is better, a laptop or a desktop?\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>\\nWhich is better, Canon or Nikon?\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>\\nWhat are the best dish detergents?\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>\\nWhat are the best cities to live in?\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>96</td>\n",
              "      <td>Which is healthier to wear, boxers or briefs?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>97</td>\n",
              "      <td>What is the difference between a blender vs a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>98</td>\n",
              "      <td>Which is better, rock or rap?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>99</td>\n",
              "      <td>Do you think imagination is better than knowle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>100</td>\n",
              "      <td>Should I learn Python or R for data analysis?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f561fe8-ce24-44f2-b4df-57ebec39e9f3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f561fe8-ce24-44f2-b4df-57ebec39e9f3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f561fe8-ce24-44f2-b4df-57ebec39e9f3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # not required for the script, building the dataframe.\n",
        " touche_topics['title'] = touche_topics['title'].apply(lambda x: x.strip())\n",
        " touche_topics['query_base'] = touche_topics['title'].apply(lambda x: get_comparation_superlation_nouns(x)[0])\n",
        " touche_topics['query_noun'] = touche_topics['title'].apply(lambda x: get_comparation_superlation_nouns(x)[1])\n",
        " touche_topics['query_synonym1'] = touche_topics['title'].apply(lambda x: get_comparation_superlation_nouns(x)[2])\n",
        " touche_topics['query_synonym2'] = touche_topics['title'].apply(lambda x: get_comparation_superlation_nouns(x)[3])\n",
        " touche_topics['query_synonym3'] = touche_topics['title'].apply(lambda x: get_comparation_superlation_nouns(x)[4])\n",
        " touche_topics['query_antonym1'] = touche_topics['title'].apply(lambda x: get_comparation_superlation_nouns(x)[5])\n",
        " touche_topics['query_antonym2'] = touche_topics['title'].apply(lambda x: get_comparation_superlation_nouns(x)[6])"
      ],
      "metadata": {
        "id": "GyZxxyTELCwh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# not required for the script, getting the dataframe output.\n",
        "touche_topics"
      ],
      "metadata": {
        "id": "YJVFL1NdLCpp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "b87b35ae-a95b-440f-97ee-c3b9e8be9073"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   number                                              title  \\\n",
              "0       1       What is the difference between sex and love?   \n",
              "1       2            Which is better, a laptop or a desktop?   \n",
              "2       3                   Which is better, Canon or Nikon?   \n",
              "3       4                 What are the best dish detergents?   \n",
              "4       5               What are the best cities to live in?   \n",
              "..    ...                                                ...   \n",
              "95     96      Which is healthier to wear, boxers or briefs?   \n",
              "96     97  What is the difference between a blender vs a ...   \n",
              "97     98                      Which is better, rock or rap?   \n",
              "98     99  Do you think imagination is better than knowle...   \n",
              "99    100      Should I learn Python or R for data analysis?   \n",
              "\n",
              "                            query_base                         query_noun  \\\n",
              "0              difference sex and love                difference sex love   \n",
              "1             better laptop or desktop                     laptop desktop   \n",
              "2                better Canon or Nikon                        Canon Nikon   \n",
              "3                 best dish detergents                         detergents   \n",
              "4                     best cities live                        cities live   \n",
              "..                                 ...                                ...   \n",
              "95     healthier wear boxers or briefs                 wear boxers briefs   \n",
              "96   difference blender food processor  difference blender food processor   \n",
              "97                  better rock or rap                           rock rap   \n",
              "98  think imagination better knowledge        think imagination knowledge   \n",
              "99     learn Python or R data analysis       learn Python R data analysis   \n",
              "\n",
              "                            query_synonym1  \\\n",
              "0            different difference sex love   \n",
              "1                      good laptop desktop   \n",
              "2                         good Canon Nikon   \n",
              "3                        better detergents   \n",
              "4                            better cities   \n",
              "..                                     ...   \n",
              "95                   healthy boxers briefs   \n",
              "96  good difference blender food processor   \n",
              "97                           good rock rap   \n",
              "98           believe imagination knowledge   \n",
              "99            teach Python R data analysis   \n",
              "\n",
              "                            query_synonym2  \\\n",
              "0               unlike difference sex love   \n",
              "1                      well laptop desktop   \n",
              "2                         well Canon Nikon   \n",
              "3                          good detergents   \n",
              "4                              good cities   \n",
              "..                                     ...   \n",
              "95                    fitter boxers briefs   \n",
              "96  well difference blender food processor   \n",
              "97                           well rock rap   \n",
              "98             guess imagination knowledge   \n",
              "99             take Python R data analysis   \n",
              "\n",
              "                               query_synonym3  \\\n",
              "0              dissimilar difference sex love   \n",
              "1                      improve laptop desktop   \n",
              "2                         improve Canon Nikon   \n",
              "3                             well detergents   \n",
              "4                                 well cities   \n",
              "..                                        ...   \n",
              "95                   salubrious boxers briefs   \n",
              "96  improve difference blender food processor   \n",
              "97                           improve rock rap   \n",
              "98              imagine imagination knowledge   \n",
              "99                 see Python R data analysis   \n",
              "\n",
              "                             query_antonym1  \\\n",
              "0                   bad difference sex love   \n",
              "1                      worse laptop desktop   \n",
              "2                         worse Canon Nikon   \n",
              "3                          worst detergents   \n",
              "4                              worst cities   \n",
              "..                                      ...   \n",
              "95                  unhealthy boxers briefs   \n",
              "96  worse difference blender food processor   \n",
              "97                           worse rock rap   \n",
              "98             forget imagination knowledge   \n",
              "99               bad Python R data analysis   \n",
              "\n",
              "                                 query_antonym2  \n",
              "0                     worse difference sex love  \n",
              "1                      different laptop desktop  \n",
              "2                         different Canon Nikon  \n",
              "3                              worse detergents  \n",
              "4                                  worse cities  \n",
              "..                                          ...  \n",
              "95                          worse boxers briefs  \n",
              "96  different difference blender food processor  \n",
              "97                           different rock rap  \n",
              "98                  worse imagination knowledge  \n",
              "99                 worse Python R data analysis  \n",
              "\n",
              "[100 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25937c78-fa39-4f0a-a49f-9c8c6bc356c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number</th>\n",
              "      <th>title</th>\n",
              "      <th>query_base</th>\n",
              "      <th>query_noun</th>\n",
              "      <th>query_synonym1</th>\n",
              "      <th>query_synonym2</th>\n",
              "      <th>query_synonym3</th>\n",
              "      <th>query_antonym1</th>\n",
              "      <th>query_antonym2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>What is the difference between sex and love?</td>\n",
              "      <td>difference sex and love</td>\n",
              "      <td>difference sex love</td>\n",
              "      <td>different difference sex love</td>\n",
              "      <td>unlike difference sex love</td>\n",
              "      <td>dissimilar difference sex love</td>\n",
              "      <td>bad difference sex love</td>\n",
              "      <td>worse difference sex love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Which is better, a laptop or a desktop?</td>\n",
              "      <td>better laptop or desktop</td>\n",
              "      <td>laptop desktop</td>\n",
              "      <td>good laptop desktop</td>\n",
              "      <td>well laptop desktop</td>\n",
              "      <td>improve laptop desktop</td>\n",
              "      <td>worse laptop desktop</td>\n",
              "      <td>different laptop desktop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Which is better, Canon or Nikon?</td>\n",
              "      <td>better Canon or Nikon</td>\n",
              "      <td>Canon Nikon</td>\n",
              "      <td>good Canon Nikon</td>\n",
              "      <td>well Canon Nikon</td>\n",
              "      <td>improve Canon Nikon</td>\n",
              "      <td>worse Canon Nikon</td>\n",
              "      <td>different Canon Nikon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>What are the best dish detergents?</td>\n",
              "      <td>best dish detergents</td>\n",
              "      <td>detergents</td>\n",
              "      <td>better detergents</td>\n",
              "      <td>good detergents</td>\n",
              "      <td>well detergents</td>\n",
              "      <td>worst detergents</td>\n",
              "      <td>worse detergents</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>What are the best cities to live in?</td>\n",
              "      <td>best cities live</td>\n",
              "      <td>cities live</td>\n",
              "      <td>better cities</td>\n",
              "      <td>good cities</td>\n",
              "      <td>well cities</td>\n",
              "      <td>worst cities</td>\n",
              "      <td>worse cities</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>96</td>\n",
              "      <td>Which is healthier to wear, boxers or briefs?</td>\n",
              "      <td>healthier wear boxers or briefs</td>\n",
              "      <td>wear boxers briefs</td>\n",
              "      <td>healthy boxers briefs</td>\n",
              "      <td>fitter boxers briefs</td>\n",
              "      <td>salubrious boxers briefs</td>\n",
              "      <td>unhealthy boxers briefs</td>\n",
              "      <td>worse boxers briefs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>97</td>\n",
              "      <td>What is the difference between a blender vs a ...</td>\n",
              "      <td>difference blender food processor</td>\n",
              "      <td>difference blender food processor</td>\n",
              "      <td>good difference blender food processor</td>\n",
              "      <td>well difference blender food processor</td>\n",
              "      <td>improve difference blender food processor</td>\n",
              "      <td>worse difference blender food processor</td>\n",
              "      <td>different difference blender food processor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>98</td>\n",
              "      <td>Which is better, rock or rap?</td>\n",
              "      <td>better rock or rap</td>\n",
              "      <td>rock rap</td>\n",
              "      <td>good rock rap</td>\n",
              "      <td>well rock rap</td>\n",
              "      <td>improve rock rap</td>\n",
              "      <td>worse rock rap</td>\n",
              "      <td>different rock rap</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>99</td>\n",
              "      <td>Do you think imagination is better than knowle...</td>\n",
              "      <td>think imagination better knowledge</td>\n",
              "      <td>think imagination knowledge</td>\n",
              "      <td>believe imagination knowledge</td>\n",
              "      <td>guess imagination knowledge</td>\n",
              "      <td>imagine imagination knowledge</td>\n",
              "      <td>forget imagination knowledge</td>\n",
              "      <td>worse imagination knowledge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>100</td>\n",
              "      <td>Should I learn Python or R for data analysis?</td>\n",
              "      <td>learn Python or R data analysis</td>\n",
              "      <td>learn Python R data analysis</td>\n",
              "      <td>teach Python R data analysis</td>\n",
              "      <td>take Python R data analysis</td>\n",
              "      <td>see Python R data analysis</td>\n",
              "      <td>bad Python R data analysis</td>\n",
              "      <td>worse Python R data analysis</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25937c78-fa39-4f0a-a49f-9c8c6bc356c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-25937c78-fa39-4f0a-a49f-9c8c6bc356c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-25937c78-fa39-4f0a-a49f-9c8c6bc356c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not required for the script, just saving the above dataframe in 'csv' format.\n",
        "touche_topics.to_csv(\"/content/drive/MyDrive/touche-2022-prototyping/touche_topics_query_expansion.csv\", index=False)"
      ],
      "metadata": {
        "id": "T-xS_sZ1LClc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metric Evaluation for the query expansion approach.\n",
        "# 1. Loading the data from the touche topics file.\n",
        "# ---\n",
        "# ---\n",
        "# IMPORTANT, relevant for script: We perform multiple retrievals for all the expanded queries.\n",
        "# Note: This might be an important modification required from the current script perspective.\n",
        "\n",
        "# Second, we use retrieval of our main query as driving matcher, and check whether for each query\n",
        "# the document is retrieved by any other of the pooled queries (at least 1, threshold).\n",
        "# If yes, we keep those documents. (We do it for first 1K documents, but we will essentially end up with ,1k documents)\n",
        "\n",
        "# After this, we select first-k relevant documents from each of the pool queries \n",
        "# The selected number of retrieved documents is optimized based on practical experience with retrieval count tuning.\n",
        "\n",
        "# Finally, those first-k relevant documents that are not present in our list from the second step are appended until 1.5k\n",
        "# document count is reached. This logic is implemented in the form of a dictionary iterator in the upcoming cells.\n",
        "# ---\n",
        "# ---\n",
        "# 2. Loading the corresponding queries into List, making predictions of k=275 (min) on the built index.\n",
        "# 3. Merging Logic: For additional queries, remove the matching documents & keep only first non-existing docs.\n",
        "# 4. Evaluation Metric: Average coverage/recall calculation for the voting based query expansion."
      ],
      "metadata": {
        "id": "ZtP-G8uRLCiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import statements for retrieval evaluation.\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "rdxzdeQ1HSYf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# not relevant for the script, as you'll be getting pool of expanded from the above function.\n",
        "touche_topics = pd.read_csv('/content/drive/MyDrive/touche-2022-prototyping/touche_topics_query_expansion.csv')\n",
        "touche_topics.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "CWfyyKM6CfNa",
        "outputId": "e6e81b1d-08d8-412b-87bf-5f2e519290fd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   number                                         title  \\\n",
              "0       1  What is the difference between sex and love?   \n",
              "1       2       Which is better, a laptop or a desktop?   \n",
              "2       3              Which is better, Canon or Nikon?   \n",
              "3       4            What are the best dish detergents?   \n",
              "4       5          What are the best cities to live in?   \n",
              "\n",
              "                 query_base           query_noun  \\\n",
              "0   difference sex and love  difference sex love   \n",
              "1  better laptop or desktop       laptop desktop   \n",
              "2     better Canon or Nikon          Canon Nikon   \n",
              "3      best dish detergents           detergents   \n",
              "4          best cities live          cities live   \n",
              "\n",
              "                  query_synonym1              query_synonym2  \\\n",
              "0  different difference sex love  unlike difference sex love   \n",
              "1            good laptop desktop         well laptop desktop   \n",
              "2               good Canon Nikon            well Canon Nikon   \n",
              "3              better detergents             good detergents   \n",
              "4                  better cities                 good cities   \n",
              "\n",
              "                   query_synonym3           query_antonym1  \\\n",
              "0  dissimilar difference sex love  bad difference sex love   \n",
              "1          improve laptop desktop     worse laptop desktop   \n",
              "2             improve Canon Nikon        worse Canon Nikon   \n",
              "3                 well detergents         worst detergents   \n",
              "4                     well cities             worst cities   \n",
              "\n",
              "              query_antonym2  \n",
              "0  worse difference sex love  \n",
              "1   different laptop desktop  \n",
              "2      different Canon Nikon  \n",
              "3           worse detergents  \n",
              "4               worse cities  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef85e06b-1fcc-4835-be28-d26651946554\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number</th>\n",
              "      <th>title</th>\n",
              "      <th>query_base</th>\n",
              "      <th>query_noun</th>\n",
              "      <th>query_synonym1</th>\n",
              "      <th>query_synonym2</th>\n",
              "      <th>query_synonym3</th>\n",
              "      <th>query_antonym1</th>\n",
              "      <th>query_antonym2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>What is the difference between sex and love?</td>\n",
              "      <td>difference sex and love</td>\n",
              "      <td>difference sex love</td>\n",
              "      <td>different difference sex love</td>\n",
              "      <td>unlike difference sex love</td>\n",
              "      <td>dissimilar difference sex love</td>\n",
              "      <td>bad difference sex love</td>\n",
              "      <td>worse difference sex love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Which is better, a laptop or a desktop?</td>\n",
              "      <td>better laptop or desktop</td>\n",
              "      <td>laptop desktop</td>\n",
              "      <td>good laptop desktop</td>\n",
              "      <td>well laptop desktop</td>\n",
              "      <td>improve laptop desktop</td>\n",
              "      <td>worse laptop desktop</td>\n",
              "      <td>different laptop desktop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Which is better, Canon or Nikon?</td>\n",
              "      <td>better Canon or Nikon</td>\n",
              "      <td>Canon Nikon</td>\n",
              "      <td>good Canon Nikon</td>\n",
              "      <td>well Canon Nikon</td>\n",
              "      <td>improve Canon Nikon</td>\n",
              "      <td>worse Canon Nikon</td>\n",
              "      <td>different Canon Nikon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>What are the best dish detergents?</td>\n",
              "      <td>best dish detergents</td>\n",
              "      <td>detergents</td>\n",
              "      <td>better detergents</td>\n",
              "      <td>good detergents</td>\n",
              "      <td>well detergents</td>\n",
              "      <td>worst detergents</td>\n",
              "      <td>worse detergents</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>What are the best cities to live in?</td>\n",
              "      <td>best cities live</td>\n",
              "      <td>cities live</td>\n",
              "      <td>better cities</td>\n",
              "      <td>good cities</td>\n",
              "      <td>well cities</td>\n",
              "      <td>worst cities</td>\n",
              "      <td>worse cities</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef85e06b-1fcc-4835-be28-d26651946554')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ef85e06b-1fcc-4835-be28-d26651946554 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ef85e06b-1fcc-4835-be28-d26651946554');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# not relevant for the script, as you'll be getting pool of expanded from the above function.\n",
        "queries = touche_topics['title']\n",
        "base_queries = touche_topics['query_base']\n",
        "noun_queries = touche_topics['query_noun']\n",
        "syn1_queries = touche_topics['query_synonym1']\n",
        "syn2_queries = touche_topics['query_synonym2']\n",
        "syn3_queries = touche_topics['query_synonym3']\n",
        "ant1_queries = touche_topics['query_antonym1']\n",
        "ant2_queries = touche_topics['query_antonym2']"
      ],
      "metadata": {
        "id": "UrvLpMQ0CfPp"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# important for making the 'pyserini' library work.\n",
        "# installing linux related stuff for pyserini\n",
        "!sudo apt-get install libomp-dev\n",
        "# installing important packages for building the new index on merged documents.\n",
        "!pip install pyserini\n",
        "!pip install faiss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "p8kzWqolCfVf",
        "outputId": "35815d89-1c47-42e8-e6cf-7f1b0a73a0ec"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libomp5\n",
            "Suggested packages:\n",
            "  libomp-doc\n",
            "The following NEW packages will be installed:\n",
            "  libomp-dev libomp5\n",
            "0 upgraded, 2 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 239 kB of archives.\n",
            "After this operation, 804 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp-dev amd64 5.0.1-1 [5,088 B]\n",
            "Fetched 239 kB in 1s (338 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 155514 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Selecting previously unselected package libomp-dev.\n",
            "Preparing to unpack .../libomp-dev_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp-dev (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp-dev (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Collecting pyserini\n",
            "  Downloading pyserini-0.16.0-py3-none-any.whl (84.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 84.6 MB 123 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pyserini) (4.64.0)\n",
            "Collecting sentencepiece>=0.1.95\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 28.5 MB/s \n",
            "\u001b[?25hCollecting pyjnius>=1.4.0\n",
            "  Downloading pyjnius-1.4.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 28.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from pyserini) (1.0.2)\n",
            "Collecting lightgbm>=3.3.2\n",
            "  Downloading lightgbm-3.3.2-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 32.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython>=0.29.21 in /usr/local/lib/python3.7/dist-packages (from pyserini) (0.29.28)\n",
            "Collecting onnxruntime>=1.8.1\n",
            "  Downloading onnxruntime-1.11.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.2 MB 24.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from pyserini) (1.3.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from pyserini) (1.4.1)\n",
            "Collecting spacy>=3.2.1\n",
            "  Downloading spacy-3.2.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 55.2 MB/s \n",
            "\u001b[?25hCollecting nmslib>=2.1.1\n",
            "  Downloading nmslib-2.1.1-cp37-cp37m-manylinux2010_x86_64.whl (13.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.5 MB 100 kB/s \n",
            "\u001b[?25hCollecting transformers>=4.6.0\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 17.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.7/dist-packages (from pyserini) (1.21.6)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=3.3.2->pyserini) (0.37.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from nmslib>=2.1.1->pyserini) (5.4.8)\n",
            "Collecting pybind11<2.6.2\n",
            "  Downloading pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n",
            "\u001b[K     |████████████████████████████████| 188 kB 22.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=1.8.1->pyserini) (2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=1.8.1->pyserini) (3.17.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->pyserini) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->pyserini) (2.8.2)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from pyjnius>=1.4.0->pyserini) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->pyserini) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->pyserini) (1.1.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (0.9.1)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 25.9 MB/s \n",
            "\u001b[?25hCollecting langcodes<4.0.0,>=3.2.0\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 49.4 MB/s \n",
            "\u001b[?25hCollecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.2 MB/s \n",
            "\u001b[?25hCollecting spacy-loggers<2.0.0,>=1.0.0\n",
            "  Downloading spacy_loggers-1.0.2-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (7.1.2)\n",
            "Collecting thinc<8.1.0,>=8.0.12\n",
            "  Downloading thinc-8.0.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (653 kB)\n",
            "\u001b[K     |████████████████████████████████| 653 kB 54.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (1.0.6)\n",
            "Collecting typer<0.5.0,>=0.3.0\n",
            "  Downloading typer-0.4.1-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (2.23.0)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
            "  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
            "Collecting typing-extensions<4.0.0.0,>=3.7.4\n",
            "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (457 kB)\n",
            "\u001b[K     |████████████████████████████████| 457 kB 35.2 MB/s \n",
            "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.6\n",
            "  Downloading catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (2.0.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (21.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (3.0.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (2.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy>=3.2.1->pyserini) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy>=3.2.1->pyserini) (3.0.8)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy>=3.2.1->pyserini) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (1.24.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->pyserini) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->pyserini) (4.11.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 10.7 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 57.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->pyserini) (3.6.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 47.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy>=3.2.1->pyserini) (2.0.1)\n",
            "Installing collected packages: typing-extensions, catalogue, typer, srsly, pyyaml, pydantic, tokenizers, thinc, spacy-loggers, spacy-legacy, sacremoses, pybind11, pathy, langcodes, huggingface-hub, transformers, spacy, sentencepiece, pyjnius, onnxruntime, nmslib, lightgbm, pyserini\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.2.0\n",
            "    Uninstalling typing-extensions-4.2.0:\n",
            "      Successfully uninstalled typing-extensions-4.2.0\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\n",
            "Successfully installed catalogue-2.0.7 huggingface-hub-0.5.1 langcodes-3.3.0 lightgbm-3.3.2 nmslib-2.1.1 onnxruntime-1.11.0 pathy-0.6.1 pybind11-2.6.1 pydantic-1.8.2 pyjnius-1.4.1 pyserini-0.16.0 pyyaml-6.0 sacremoses-0.0.49 sentencepiece-0.1.96 spacy-3.2.4 spacy-legacy-3.0.9 spacy-loggers-1.0.2 srsly-2.4.3 thinc-8.0.15 tokenizers-0.12.1 transformers-4.18.0 typer-0.4.1 typing-extensions-3.10.0.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "catalogue",
                  "spacy",
                  "srsly",
                  "thinc",
                  "typing_extensions"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss\n",
            "  Downloading faiss-1.5.3-cp37-cp37m-manylinux1_x86_64.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from faiss) (1.21.6)\n",
            "Installing collected packages: faiss\n",
            "Successfully installed faiss-1.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# relevant for the script, loading the already stored and built index.\n",
        "from pyserini.search.lucene import LuceneSearcher\n",
        "searcher_opt = LuceneSearcher('/content/drive/MyDrive/touche-2022-prototyping/indexes/baseline_index')\n",
        "searcher_opt.set_bm25(1.2, 0.68)"
      ],
      "metadata": {
        "id": "1pCBM-mDCfXo"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# relevant for the script, getting the driving query retrieval in the solution dictionary.\n",
        "solution_dict = {}\n",
        "for id_, q_ in zip(touche_topics['number'], queries):\n",
        "    hits = searcher_opt.search(q_.strip(), k=1500)\n",
        "    d_list = []\n",
        "    for h_ in hits:\n",
        "        # d_= h_.docid.split('___')[0]\n",
        "        d_= h_.docid\n",
        "        if d_ not in d_list:\n",
        "            d_list.append(d_)\n",
        "    solution_dict[id_] = d_list"
      ],
      "metadata": {
        "id": "7CBnZjvBCfcR"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# relevant for the script, getting the noun query retrievals.\n",
        "solution_dict_noun = {}\n",
        "for id_, q_ in zip(touche_topics['number'], noun_queries):\n",
        "    hits = searcher_opt.search(q_.strip(), k=3000)\n",
        "    d_list = []\n",
        "    for h_ in hits:\n",
        "        # d_= h_.docid.split('___')[0]\n",
        "        d_= h_.docid\n",
        "        if d_ not in d_list:\n",
        "            d_list.append(d_)\n",
        "    solution_dict_noun[id_] = d_list"
      ],
      "metadata": {
        "id": "MzugyNuvIOVF"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# relevant for the script, getting the base query retrievals.\n",
        "solution_dict_base = {}\n",
        "for id_, q_ in zip(touche_topics['number'], base_queries):\n",
        "    hits = searcher_opt.search(q_.strip(), k=3000)\n",
        "    d_list = []\n",
        "    for h_ in hits:\n",
        "        # d_= h_.docid.split('___')[0]\n",
        "        d_= h_.docid\n",
        "        if d_ not in d_list:\n",
        "            d_list.append(d_)\n",
        "    solution_dict_base[id_] = d_list"
      ],
      "metadata": {
        "id": "FTwhH2HxJC8j"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# relevant for the script, getting the syn1 query retrievals.\n",
        "solution_dict_syn1 = {}\n",
        "for id_, q_ in zip(touche_topics['number'], syn1_queries):\n",
        "    hits = searcher_opt.search(q_.strip(), k=3000)\n",
        "    d_list = []\n",
        "    for h_ in hits:\n",
        "        # d_= h_.docid.split('___')[0]\n",
        "        d_= h_.docid\n",
        "        if d_ not in d_list:\n",
        "            d_list.append(d_)\n",
        "    solution_dict_syn1[id_] = d_list"
      ],
      "metadata": {
        "id": "4K7AsnsaJC_G"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# relevant for the script, getting the syn2 query retrievals.\n",
        "solution_dict_syn2 = {}\n",
        "for id_, q_ in zip(touche_topics['number'], syn2_queries):\n",
        "    hits = searcher_opt.search(q_.strip(), k=3000)\n",
        "    d_list = []\n",
        "    for h_ in hits:\n",
        "        # d_= h_.docid.split('___')[0]\n",
        "        d_= h_.docid\n",
        "        if d_ not in d_list:\n",
        "            d_list.append(d_)\n",
        "    solution_dict_syn2[id_] = d_list"
      ],
      "metadata": {
        "id": "jUegp4GkpOvg"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# relevant for the script, getting the syn3 query retrievals.\n",
        "solution_dict_syn3 = {}\n",
        "for id_, q_ in zip(touche_topics['number'], syn3_queries):\n",
        "    hits = searcher_opt.search(q_.strip(), k=3000)\n",
        "    d_list = []\n",
        "    for h_ in hits:\n",
        "        # d_= h_.docid.split('___')[0]\n",
        "        d_= h_.docid\n",
        "        if d_ not in d_list:\n",
        "            d_list.append(d_)\n",
        "    solution_dict_syn3[id_] = d_list"
      ],
      "metadata": {
        "id": "WoJI1JM5pjO4"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# relevant for the script, getting the ant1 query retrievals.\n",
        "solution_dict_ant1 = {}\n",
        "for id_, q_ in zip(touche_topics['number'], ant1_queries):\n",
        "    hits = searcher_opt.search(q_.strip(), k=3000)\n",
        "    d_list = []\n",
        "    for h_ in hits:\n",
        "        # d_= h_.docid.split('___')[0]\n",
        "        d_= h_.docid\n",
        "        if d_ not in d_list:\n",
        "            d_list.append(d_)\n",
        "    solution_dict_ant1[id_] = d_list"
      ],
      "metadata": {
        "id": "__ng1YsbJDCU"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# relevant for the script, getting the ant2 query retrievals.\n",
        "solution_dict_ant2 = {}\n",
        "for id_, q_ in zip(touche_topics['number'], ant2_queries):\n",
        "    hits = searcher_opt.search(q_.strip(), k=3000)\n",
        "    d_list = []\n",
        "    for h_ in hits:\n",
        "        # d_= h_.docid.split('___')[0]\n",
        "        d_= h_.docid\n",
        "        if d_ not in d_list:\n",
        "            d_list.append(d_)\n",
        "    solution_dict_ant2[id_] = d_list"
      ],
      "metadata": {
        "id": "QV1dPuuJpogn"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTANT: Main document merging logic, you might require a function or I'll recommend straight up adding it in the voting/expansion script.\n",
        "# Solution dictionary final below, will store list of all document (but not in ordered manner) to be fed into monoT5.\n",
        "# The order doesn't matter as monoT5 ingnores all the associated scores.\n",
        "solution_dict_fin = {}\n",
        "# iterating over all the pooled queries that we have created, plus our driving query.\n",
        "for (k,v), (k1,v1), (k2,v2), (k3,v3), (k4,v4), (k5,v5), (k6,v6), (k7,v7) \\\n",
        "    in zip(solution_dict.items(), solution_dict_noun.items(), solution_dict_base.items(), solution_dict_syn1.items(), \\\n",
        "           solution_dict_syn2.items(), solution_dict_syn3.items(), solution_dict_ant1.items(), solution_dict_ant2.items()):    \n",
        "    # check for all k's being equal is quite unnecessary though.\n",
        "    if k == k1 and k1 == k2 and k2 == k3 and k3 == k4 and k4 == k5 and k5 == k6 and k6 == k7:\n",
        "        # for storing the list of 1500 relevant documents as per our merging logic.\n",
        "        l_temp = []\n",
        "\n",
        "        # finding commonality amongst documents from different queries.\n",
        "        # below 'v' represents documents from driving main query.\n",
        "        # we essentially check, whether the given document v_ in v is present\n",
        "        # in any of the other retrievals by other pool of expanded queries.\n",
        "        # If, v_ is present in any of the documents we add it into the l_temp.\n",
        "        v_x = v[:1000] # limiting only to 1500 entries only.\n",
        "        for v_ in v_x:\n",
        "            c_b = 0\n",
        "            if v_ in v1:\n",
        "                c_b = c_b + 1\n",
        "            if v_ in v2:\n",
        "                c_b = c_b + 1\n",
        "            if v_ in v3:\n",
        "                c_b = c_b + 1\n",
        "            if v_ in v4:\n",
        "                c_b = c_b + 1\n",
        "            if v_ in v5:\n",
        "                c_b = c_b + 1\n",
        "            if c_b >= 1:\n",
        "                l_temp.append(v_)\n",
        "\n",
        "        # for the query we will append documents\n",
        "        # till it reaches the 1125 document count for l_temp.\n",
        "        diff_ = 1125 - len(l_temp)\n",
        "        \n",
        "        # appending document logic.\n",
        "        c_ = 0\n",
        "        for v1_ in v1: # appending base query documents.\n",
        "            if v1_ not in l_temp: # only relevant non-existing docs added.\n",
        "                l_temp.append(v1_)\n",
        "            elif c_ > diff_:\n",
        "                break\n",
        "            c_ = c_ + 1\n",
        "\n",
        "        c_ = 0\n",
        "        for v2_ in v2: # appending noun query documents.\n",
        "            if v2_ not in l_temp: # only relevant non-existing docs added.\n",
        "                l_temp.append(v2_)\n",
        "            elif c_ > 150:\n",
        "                break\n",
        "            c_ = c_ + 1\n",
        "\n",
        "        c_ = 0\n",
        "        for v3_ in v3: # appending syn1 documents.\n",
        "            if v3_ not in l_temp: # only relevant non-existing docs added.\n",
        "                l_temp.append(v3_)\n",
        "            elif c_ > 75:\n",
        "                break\n",
        "            c_ = c_ + 1\n",
        "\n",
        "        c_ = 0\n",
        "        for v4_ in v4: # appending syn2 documents.\n",
        "            if v4_ not in l_temp: # only relevant non-existing docs added.\n",
        "                l_temp.append(v4_)\n",
        "            elif c_ > 46:\n",
        "                break\n",
        "            c_ = c_ + 1\n",
        "\n",
        "        c_ = 0\n",
        "        for v5_ in v5: # appending syn3 documents.\n",
        "            if v5_ not in l_temp: # only relevant non-existing docs added.\n",
        "                l_temp.append(v5_)\n",
        "            elif c_ > 45:\n",
        "                break\n",
        "            c_ = c_ + 1\n",
        "\n",
        "        c_ = 0\n",
        "        for v6_ in v6: # appending ant documents.\n",
        "            if v6_ not in l_temp: # only relevant non-existing docs added.\n",
        "                l_temp.append(v6_)\n",
        "            elif c_ > 30:\n",
        "                break\n",
        "            c_ = c_ + 1\n",
        "\n",
        "        c_ = 0\n",
        "        for v7_ in v7: # appending ant documents.\n",
        "            if v7_ not in l_temp: # only relevant non-existing docs added.\n",
        "                l_temp.append(v7_)\n",
        "            elif c_ > 30:\n",
        "                break\n",
        "            c_ = c_ + 1\n",
        "        \n",
        "        c_ = 0\n",
        "        for v8_ in v_x: # appending org. documents.\n",
        "            if v8_ not in l_temp: # only relevant non-existing docs added.\n",
        "                l_temp.append(v8_)\n",
        "            elif c_ > 175:\n",
        "                break\n",
        "            c_ = c_ + 1\n",
        "\n",
        "        for v9_ in v2: # appending base documents.\n",
        "            if v9_ not in l_temp: # only relevant non-existing docs added.\n",
        "                l_temp.append(v9_)\n",
        "\n",
        "        solution_dict_fin[k] = l_temp[:1500]"
      ],
      "metadata": {
        "id": "tom9DCNpJDOh"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing out the number of documents in the retrieval.\n",
        "i = 0\n",
        "for x, y in solution_dict_fin.items():\n",
        "    print(x, len(y))\n",
        "    if i > 10:\n",
        "        break\n",
        "    i = i+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdptFGI1q_89",
        "outputId": "40702345-907c-438f-f8ba-1ed3af621d63"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 1500\n",
            "2 1500\n",
            "3 1500\n",
            "4 1500\n",
            "5 1500\n",
            "6 1500\n",
            "7 1500\n",
            "8 1500\n",
            "9 1500\n",
            "10 1500\n",
            "11 1500\n",
            "12 1500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# not required for the script, getting merged solution dict calculating the average recall/coverage metric.\n",
        "metric_dict_vote = {}\n",
        "metric_dict_bm25 = {}\n",
        "for (id_a, dense_list), (id_b, bm25_list) in zip(solution_dict_fin.items(), solution_dict.items()):\n",
        "    # 1.\n",
        "    d_list = []\n",
        "    for h_ in dense_list:\n",
        "        d_= h_.split('___')[0]\n",
        "        if d_ not in d_list:\n",
        "            d_list.append(d_)\n",
        "    metric_dict_vote[id_a] = d_list\n",
        "    # 2.\n",
        "    d_list = []\n",
        "    for h_ in bm25_list:\n",
        "        d_= h_.split('___')[0]\n",
        "        if d_ not in d_list:\n",
        "            d_list.append(d_)\n",
        "    metric_dict_bm25[id_b] = d_list"
      ],
      "metadata": {
        "id": "uFgAdKqr8kL1"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# not required for the script, metric calculation part.\n",
        "i = 0\n",
        "for x, y in metric_dict_vote.items():\n",
        "    print(x, len(y))\n",
        "    if i >= 10:\n",
        "        break\n",
        "    i = i+1\n",
        "print('\\n')\n",
        "i = 0\n",
        "for x, y in metric_dict_bm25.items():\n",
        "    print(x, len(y))\n",
        "    if i >= 10:\n",
        "        break\n",
        "    i = i+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsBCgYdJ-eGr",
        "outputId": "9ce164d0-c807-4cb0-bed6-cc191ef5837d"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 533\n",
            "2 678\n",
            "3 439\n",
            "4 659\n",
            "5 778\n",
            "6 679\n",
            "7 510\n",
            "8 1041\n",
            "9 568\n",
            "10 697\n",
            "11 549\n",
            "\n",
            "\n",
            "1 630\n",
            "2 679\n",
            "3 440\n",
            "4 728\n",
            "5 843\n",
            "6 704\n",
            "7 512\n",
            "8 1041\n",
            "9 574\n",
            "10 595\n",
            "11 549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# not required for the script, metric calculation part.\n",
        "# loading the baseline qrel files.\n",
        "new_rel_2021 = pd.read_csv('/content/drive/MyDrive/touche-2022-prototyping/touche_ground_truth.csv')\n",
        "new_rel_2021.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dC0QdIdAJDXT",
        "outputId": "7a6ecf57-c799-45e5-93fe-85580313661d"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   qid  no                        doc  rel\n",
              "0    1   0  clueweb12-0001wb-05-12311    0\n",
              "1    1   0  clueweb12-1811wb-62-08424    1\n",
              "2    1   0  clueweb12-1811wb-62-08423    1\n",
              "3    1   0  clueweb12-1217wb-47-14048    0\n",
              "4    1   0  clueweb12-1811wb-62-08425    1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-efe0ec05-3e37-4c4a-a1ff-9f20a8adce3f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>no</th>\n",
              "      <th>doc</th>\n",
              "      <th>rel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>clueweb12-0001wb-05-12311</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>clueweb12-1811wb-62-08424</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>clueweb12-1811wb-62-08423</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>clueweb12-1217wb-47-14048</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>clueweb12-1811wb-62-08425</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-efe0ec05-3e37-4c4a-a1ff-9f20a8adce3f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-efe0ec05-3e37-4c4a-a1ff-9f20a8adce3f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-efe0ec05-3e37-4c4a-a1ff-9f20a8adce3f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# not required for the script, metric calculation part.\n",
        "from collections import defaultdict\n",
        "ground_truth_dict = defaultdict(list)\n",
        "rel0_truth_dict = defaultdict(list)\n",
        "rel1_truth_dict = defaultdict(list)\n",
        "rel2_truth_dict = defaultdict(list)\n",
        "\n",
        "for i_, d_, x_ in zip(new_rel_2021['qid'], new_rel_2021['doc'], new_rel_2021['rel']):\n",
        "    i_ = int(i_)\n",
        "    d_ = str(d_)    \n",
        "    if int(x_) > 0:\n",
        "        ground_truth_dict[i_].append(d_)\n",
        "    if int(x_) == 0:\n",
        "        rel0_truth_dict[i_].append(d_)\n",
        "    if int(x_) == 1:\n",
        "        rel1_truth_dict[i_].append(d_)\n",
        "    if int(x_) == 2:\n",
        "        rel2_truth_dict[i_].append(d_)"
      ],
      "metadata": {
        "id": "Ih9A6cM_JDa-"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# not required for the script, metric calculation part.\n",
        "# the final dictionaries for basic metric evaluation and analysis.\n",
        "# Average percentage common, Hit-once and Hit-all metric basic definition.\n",
        "hit_one = 0\n",
        "hit_all = 0\n",
        "total = 100\n",
        "per_comm_avg = 0\n",
        "\n",
        "for id_i, doc_i in ground_truth_dict.items():\n",
        "    doc_i = set(doc_i)\n",
        "    for id_j , doc_j in metric_dict_vote.items():\n",
        "        doc_j = set(doc_j)\n",
        "        if id_i == id_j:\n",
        "            if doc_j.intersection(doc_i):\n",
        "                hit_one += 1\n",
        "            if doc_j.issuperset(doc_i):\n",
        "                hit_all += 1\n",
        "            per_comm_avg += len(doc_j.intersection(doc_i))/len(doc_i)\n",
        "            break\n",
        "\n",
        "print(f'Hit one: {round(hit_one / total, 4)}')\n",
        "print(f'Hit all: {round(hit_all / total, 4)}')\n",
        "print(f'Average common ratio: {round(per_comm_avg / total, 4)}')\n",
        "\n",
        "hit0_one = 0\n",
        "hit0_all = 0\n",
        "per0_comm_avg = 0\n",
        "\n",
        "for id_i, doc_i in rel0_truth_dict.items():\n",
        "    doc_i = set(doc_i)\n",
        "    for id_j , doc_j in metric_dict_vote.items():\n",
        "        doc_j = set(doc_j)\n",
        "        if id_i == id_j:\n",
        "            if doc_j.intersection(doc_i):\n",
        "                hit0_one += 1\n",
        "            if doc_j.issuperset(doc_i):\n",
        "                hit0_all += 1\n",
        "            per0_comm_avg += len(doc_j.intersection(doc_i))/len(doc_i)\n",
        "            break\n",
        "\n",
        "print(f'Zero Relevance, Hit one: {round(hit0_one / total, 4)}')\n",
        "print(f'Zero Relevance, Hit all: {round(hit0_all / total, 4)}')\n",
        "print(f'Zero Relevance, Average common ratio: {round(per0_comm_avg / total, 4)}')\n",
        "\n",
        "hit1_one = 0\n",
        "hit1_all = 0\n",
        "per1_comm_avg = 0\n",
        "\n",
        "for id_i, doc_i in rel1_truth_dict.items():\n",
        "    doc_i = set(doc_i)\n",
        "    for id_j , doc_j in metric_dict_vote.items():\n",
        "        doc_j = set(doc_j)\n",
        "        if id_i == id_j:\n",
        "            if doc_j.intersection(doc_i):\n",
        "                hit1_one += 1\n",
        "            if doc_j.issuperset(doc_i):\n",
        "                hit1_all += 1\n",
        "            per1_comm_avg += len(doc_j.intersection(doc_i))/len(doc_i)\n",
        "            break\n",
        "\n",
        "print(f'One Relevance, Hit one: {round(hit1_one / total, 4)}')\n",
        "print(f'One Relevance, Hit all: {round(hit1_all / total, 4)}')\n",
        "print(f'One Relevance, Average common ratio: {round(per1_comm_avg / total, 4)}')\n",
        "\n",
        "hit2_one = 0\n",
        "hit2_all = 0\n",
        "per2_comm_avg = 0\n",
        "\n",
        "for id_i, doc_i in rel2_truth_dict.items():\n",
        "    doc_i = set(doc_i)\n",
        "    for id_j , doc_j in metric_dict_vote.items():\n",
        "        doc_j = set(doc_j)\n",
        "        if id_i == id_j:\n",
        "            if doc_j.intersection(doc_i):\n",
        "                hit2_one += 1\n",
        "            if doc_j.issuperset(doc_i):\n",
        "                hit2_all += 1\n",
        "            per2_comm_avg += len(doc_j.intersection(doc_i))/len(doc_i)\n",
        "            break\n",
        "\n",
        "print(f'Two Relevance, Hit one: {round(hit2_one / total, 4)}')\n",
        "print(f'Two Relevance, Hit all: {round(hit2_all / total, 4)}')\n",
        "print(f'Two Relevance, Average common ratio: {round(per2_comm_avg / total, 4)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbXYREP_CffH",
        "outputId": "b57680b4-94f6-4396-9eeb-90465676f98d"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit one: 1.0\n",
            "Hit all: 0.3\n",
            "Average common ratio: 0.8757\n",
            "Zero Relevance, Hit one: 1.0\n",
            "Zero Relevance, Hit all: 0.08\n",
            "Zero Relevance, Average common ratio: 0.7573\n",
            "One Relevance, Hit one: 0.99\n",
            "One Relevance, Hit all: 0.4\n",
            "One Relevance, Average common ratio: 0.8598\n",
            "Two Relevance, Hit one: 0.9\n",
            "Two Relevance, Hit all: 0.49\n",
            "Two Relevance, Average common ratio: 0.8025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# not required for the script, metric calculation part.\n",
        "# the final dictionaries for basic metric evaluation and analysis.\n",
        "# Average percentage common, Hit-once and Hit-all metric basic definition.\n",
        "# not required for the script, metric calculation part.\n",
        "# the final dictionaries for basic metric evaluation and analysis.\n",
        "# Average percentage common, Hit-once and Hit-all metric basic definition.\n",
        "hit_one = 0\n",
        "hit_all = 0\n",
        "total = 100\n",
        "per_comm_avg = 0\n",
        "\n",
        "for id_i, doc_i in ground_truth_dict.items():\n",
        "    doc_i = set(doc_i)\n",
        "    for id_j , doc_j in metric_dict_bm25.items():\n",
        "        doc_j = set(doc_j)\n",
        "        if id_i == id_j:\n",
        "            if doc_j.intersection(doc_i):\n",
        "                hit_one += 1\n",
        "            if doc_j.issuperset(doc_i):\n",
        "                hit_all += 1\n",
        "            per_comm_avg += len(doc_j.intersection(doc_i))/len(doc_i)\n",
        "            break\n",
        "\n",
        "print(f'Hit one: {round(hit_one / total, 4)}')\n",
        "print(f'Hit all: {round(hit_all / total, 4)}')\n",
        "print(f'Average common ratio: {round(per_comm_avg / total, 4)}')\n",
        "\n",
        "hit0_one = 0\n",
        "hit0_all = 0\n",
        "per0_comm_avg = 0\n",
        "\n",
        "for id_i, doc_i in rel0_truth_dict.items():\n",
        "    doc_i = set(doc_i)\n",
        "    for id_j , doc_j in metric_dict_bm25.items():\n",
        "        doc_j = set(doc_j)\n",
        "        if id_i == id_j:\n",
        "            if doc_j.intersection(doc_i):\n",
        "                hit0_one += 1\n",
        "            if doc_j.issuperset(doc_i):\n",
        "                hit0_all += 1\n",
        "            per0_comm_avg += len(doc_j.intersection(doc_i))/len(doc_i)\n",
        "            break\n",
        "\n",
        "print(f'Zero Relevance, Hit one: {round(hit0_one / total, 4)}')\n",
        "print(f'Zero Relevance, Hit all: {round(hit0_all / total, 4)}')\n",
        "print(f'Zero Relevance, Average common ratio: {round(per0_comm_avg / total, 4)}')\n",
        "\n",
        "hit1_one = 0\n",
        "hit1_all = 0\n",
        "per1_comm_avg = 0\n",
        "\n",
        "for id_i, doc_i in rel1_truth_dict.items():\n",
        "    doc_i = set(doc_i)\n",
        "    for id_j , doc_j in metric_dict_bm25.items():\n",
        "        doc_j = set(doc_j)\n",
        "        if id_i == id_j:\n",
        "            if doc_j.intersection(doc_i):\n",
        "                hit1_one += 1\n",
        "            if doc_j.issuperset(doc_i):\n",
        "                hit1_all += 1\n",
        "            per1_comm_avg += len(doc_j.intersection(doc_i))/len(doc_i)\n",
        "            break\n",
        "\n",
        "print(f'One Relevance, Hit one: {round(hit1_one / total, 4)}')\n",
        "print(f'One Relevance, Hit all: {round(hit1_all / total, 4)}')\n",
        "print(f'One Relevance, Average common ratio: {round(per1_comm_avg / total, 4)}')\n",
        "\n",
        "hit2_one = 0\n",
        "hit2_all = 0\n",
        "per2_comm_avg = 0\n",
        "\n",
        "for id_i, doc_i in rel2_truth_dict.items():\n",
        "    doc_i = set(doc_i)\n",
        "    for id_j , doc_j in metric_dict_bm25.items():\n",
        "        doc_j = set(doc_j)\n",
        "        if id_i == id_j:\n",
        "            if doc_j.intersection(doc_i):\n",
        "                hit2_one += 1\n",
        "            if doc_j.issuperset(doc_i):\n",
        "                hit2_all += 1\n",
        "            per2_comm_avg += len(doc_j.intersection(doc_i))/len(doc_i)\n",
        "            break\n",
        "\n",
        "print(f'Two Relevance, Hit one: {round(hit2_one / total, 4)}')\n",
        "print(f'Two Relevance, Hit all: {round(hit2_all / total, 4)}')\n",
        "print(f'Two Relevance, Average common ratio: {round(per2_comm_avg / total, 4)}')"
      ],
      "metadata": {
        "id": "SVV07N1fy8wj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bef68fe-32aa-43bb-e375-bfc89c23aecc"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit one: 1.0\n",
            "Hit all: 0.29\n",
            "Average common ratio: 0.8744\n",
            "Zero Relevance, Hit one: 1.0\n",
            "Zero Relevance, Hit all: 0.08\n",
            "Zero Relevance, Average common ratio: 0.7544\n",
            "One Relevance, Hit one: 0.99\n",
            "One Relevance, Hit all: 0.39\n",
            "One Relevance, Average common ratio: 0.854\n",
            "Two Relevance, Hit one: 0.9\n",
            "Two Relevance, Hit all: 0.49\n",
            "Two Relevance, Average common ratio: 0.8025\n"
          ]
        }
      ]
    }
  ]
}